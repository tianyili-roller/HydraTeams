// @ts-nocheck
// This file is auto-generated by @hey-api/openapi-ts

import * as z from 'zod';

export const zAddUploadPartRequest = z.object({
    data: z.string()
});

/**
 * Represents an individual Admin API key in an org.
 */
export const zAdminApiKey = z.object({
    object: z.string(),
    id: z.string(),
    name: z.string(),
    redacted_value: z.string(),
    value: z.optional(z.string()),
    created_at: z.coerce.bigint().min(BigInt('-9223372036854775808'), { error: 'Invalid value: Expected int64 to be >= -9223372036854775808' }).max(BigInt('9223372036854775807'), { error: 'Invalid value: Expected int64 to be <= 9223372036854775807' }),
    last_used_at: z.union([
        z.coerce.bigint().min(BigInt('-9223372036854775808'), { error: 'Invalid value: Expected int64 to be >= -9223372036854775808' }).max(BigInt('9223372036854775807'), { error: 'Invalid value: Expected int64 to be <= 9223372036854775807' }),
        z.null()
    ]),
    owner: z.object({
        type: z.optional(z.string()),
        object: z.optional(z.string()),
        id: z.optional(z.string()),
        name: z.optional(z.string()),
        created_at: z.optional(z.coerce.bigint().min(BigInt('-9223372036854775808'), { error: 'Invalid value: Expected int64 to be >= -9223372036854775808' }).max(BigInt('9223372036854775807'), { error: 'Invalid value: Expected int64 to be <= 9223372036854775807' })),
        role: z.optional(z.string())
    })
});

export const zApiKeyList = z.object({
    object: z.optional(z.string()),
    data: z.optional(z.array(zAdminApiKey)),
    has_more: z.optional(z.boolean()),
    first_id: z.optional(z.string()),
    last_id: z.optional(z.string())
});

export const zAssistantSupportedModels = z.enum([
    'gpt-4.1',
    'gpt-4.1-mini',
    'gpt-4.1-nano',
    'gpt-4.1-2025-04-14',
    'gpt-4.1-mini-2025-04-14',
    'gpt-4.1-nano-2025-04-14',
    'o3-mini',
    'o3-mini-2025-01-31',
    'o1',
    'o1-2024-12-17',
    'gpt-4o',
    'gpt-4o-2024-11-20',
    'gpt-4o-2024-08-06',
    'gpt-4o-2024-05-13',
    'gpt-4o-mini',
    'gpt-4o-mini-2024-07-18',
    'gpt-4.5-preview',
    'gpt-4.5-preview-2025-02-27',
    'gpt-4-turbo',
    'gpt-4-turbo-2024-04-09',
    'gpt-4-0125-preview',
    'gpt-4-turbo-preview',
    'gpt-4-1106-preview',
    'gpt-4-vision-preview',
    'gpt-4',
    'gpt-4-0314',
    'gpt-4-0613',
    'gpt-4-32k',
    'gpt-4-32k-0314',
    'gpt-4-32k-0613',
    'gpt-3.5-turbo',
    'gpt-3.5-turbo-16k',
    'gpt-3.5-turbo-0613',
    'gpt-3.5-turbo-1106',
    'gpt-3.5-turbo-0125',
    'gpt-3.5-turbo-16k-0613'
]);

/**
 * Code interpreter tool
 */
export const zAssistantToolsCode = z.object({
    type: z.enum(['code_interpreter'])
});

/**
 * FileSearch tool
 */
export const zAssistantToolsFileSearchTypeOnly = z.object({
    type: z.enum(['file_search'])
});

/**
 * Specifies a tool the model should use. Use to force the model to call a specific tool.
 */
export const zAssistantsNamedToolChoice = z.object({
    type: z.enum([
        'function',
        'code_interpreter',
        'file_search'
    ]),
    function: z.optional(z.object({
        name: z.string()
    }))
});

/**
 * Controls which (if any) tool is called by the model.
 * `none` means the model will not call any tools and instead generates a message.
 * `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
 * `required` means the model must call one or more tools before responding to the user.
 * Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
 *
 */
export const zAssistantsApiToolChoiceOption = z.union([
    z.literal('none'),
    z.literal('auto'),
    z.literal('required'),
    zAssistantsNamedToolChoice
]);

/**
 * The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`.
 *
 */
export const zAudioResponseFormat = z.enum([
    'json',
    'text',
    'srt',
    'verbose_json',
    'vtt'
]);

/**
 * The service account that performed the audit logged action.
 */
export const zAuditLogActorServiceAccount = z.object({
    id: z.optional(z.string())
});

/**
 * The user who performed the audit logged action.
 */
export const zAuditLogActorUser = z.object({
    id: z.optional(z.string()),
    email: z.optional(z.string())
});

/**
 * The API Key used to perform the audit logged action.
 */
export const zAuditLogActorApiKey = z.object({
    id: z.optional(z.string()),
    type: z.optional(z.enum(['user', 'service_account'])),
    user: z.optional(zAuditLogActorUser),
    service_account: z.optional(zAuditLogActorServiceAccount)
});

/**
 * The session in which the audit logged action was performed.
 */
export const zAuditLogActorSession = z.object({
    user: z.optional(zAuditLogActorUser),
    ip_address: z.optional(z.string())
});

/**
 * The actor who performed the audit logged action.
 */
export const zAuditLogActor = z.object({
    type: z.optional(z.enum(['session', 'api_key'])),
    session: z.optional(zAuditLogActorSession),
    api_key: z.optional(zAuditLogActorApiKey)
});

/**
 * The event type.
 */
export const zAuditLogEventType = z.enum([
    'api_key.created',
    'api_key.updated',
    'api_key.deleted',
    'checkpoint_permission.created',
    'checkpoint_permission.deleted',
    'invite.sent',
    'invite.accepted',
    'invite.deleted',
    'login.succeeded',
    'login.failed',
    'logout.succeeded',
    'logout.failed',
    'organization.updated',
    'project.created',
    'project.updated',
    'project.archived',
    'service_account.created',
    'service_account.updated',
    'service_account.deleted',
    'rate_limit.updated',
    'rate_limit.deleted',
    'user.added',
    'user.updated',
    'user.deleted'
]);

/**
 * A log of a user action or configuration change within this organization.
 */
export const zAuditLog = z.object({
    id: z.string(),
    type: zAuditLogEventType,
    effective_at: z.int(),
    project: z.optional(z.object({
        id: z.optional(z.string()),
        name: z.optional(z.string())
    })),
    actor: zAuditLogActor,
    'api_key.created': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            scopes: z.optional(z.array(z.string()))
        }))
    })),
    'api_key.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            scopes: z.optional(z.array(z.string()))
        }))
    })),
    'api_key.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'checkpoint_permission.created': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            project_id: z.optional(z.string()),
            fine_tuned_model_checkpoint: z.optional(z.string())
        }))
    })),
    'checkpoint_permission.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'invite.sent': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            email: z.optional(z.string()),
            role: z.optional(z.string())
        }))
    })),
    'invite.accepted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'invite.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'login.failed': z.optional(z.object({
        error_code: z.optional(z.string()),
        error_message: z.optional(z.string())
    })),
    'logout.failed': z.optional(z.object({
        error_code: z.optional(z.string()),
        error_message: z.optional(z.string())
    })),
    'organization.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            title: z.optional(z.string()),
            description: z.optional(z.string()),
            name: z.optional(z.string()),
            settings: z.optional(z.object({
                threads_ui_visibility: z.optional(z.string()),
                usage_dashboard_visibility: z.optional(z.string())
            }))
        }))
    })),
    'project.created': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            name: z.optional(z.string()),
            title: z.optional(z.string())
        }))
    })),
    'project.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            title: z.optional(z.string())
        }))
    })),
    'project.archived': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'rate_limit.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            max_requests_per_1_minute: z.optional(z.int()),
            max_tokens_per_1_minute: z.optional(z.int()),
            max_images_per_1_minute: z.optional(z.int()),
            max_audio_megabytes_per_1_minute: z.optional(z.int()),
            max_requests_per_1_day: z.optional(z.int()),
            batch_1_day_max_input_tokens: z.optional(z.int())
        }))
    })),
    'rate_limit.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'service_account.created': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            role: z.optional(z.string())
        }))
    })),
    'service_account.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            role: z.optional(z.string())
        }))
    })),
    'service_account.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'user.added': z.optional(z.object({
        id: z.optional(z.string()),
        data: z.optional(z.object({
            role: z.optional(z.string())
        }))
    })),
    'user.updated': z.optional(z.object({
        id: z.optional(z.string()),
        changes_requested: z.optional(z.object({
            role: z.optional(z.string())
        }))
    })),
    'user.deleted': z.optional(z.object({
        id: z.optional(z.string())
    })),
    'certificate.created': z.optional(z.object({
        id: z.optional(z.string()),
        name: z.optional(z.string())
    })),
    'certificate.updated': z.optional(z.object({
        id: z.optional(z.string()),
        name: z.optional(z.string())
    })),
    'certificate.deleted': z.optional(z.object({
        id: z.optional(z.string()),
        name: z.optional(z.string()),
        certificate: z.optional(z.string())
    })),
    'certificates.activated': z.optional(z.object({
        certificates: z.optional(z.array(z.object({
            id: z.optional(z.string()),
            name: z.optional(z.string())
        })))
    })),
    'certificates.deactivated': z.optional(z.object({
        certificates: z.optional(z.array(z.object({
            id: z.optional(z.string()),
            name: z.optional(z.string())
        })))
    }))
});

/**
 * Auto Chunking Strategy
 *
 * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
 */
export const zAutoChunkingStrategyRequestParam = z.object({
    type: z.enum(['auto'])
});

/**
 * The per-line object of the batch input file
 */
export const zBatchRequestInput = z.object({
    custom_id: z.optional(z.string()),
    method: z.optional(z.enum(['POST'])),
    url: z.optional(z.string())
});

/**
 * The per-line object of the batch output and error files
 */
export const zBatchRequestOutput = z.object({
    id: z.optional(z.string()),
    custom_id: z.optional(z.string()),
    response: z.optional(z.union([
        z.object({
            status_code: z.optional(z.int()),
            request_id: z.optional(z.string()),
            body: z.optional(z.record(z.string(), z.unknown()))
        }),
        z.null()
    ])),
    error: z.optional(z.union([
        z.object({
            code: z.optional(z.string()),
            message: z.optional(z.string())
        }),
        z.null()
    ]))
});

/**
 * Represents an individual `certificate` uploaded to the organization.
 */
export const zCertificate = z.object({
    object: z.enum([
        'certificate',
        'organization.certificate',
        'organization.project.certificate'
    ]),
    id: z.string(),
    name: z.string(),
    created_at: z.int(),
    certificate_details: z.object({
        valid_at: z.optional(z.int()),
        expires_at: z.optional(z.int()),
        content: z.optional(z.string())
    }),
    active: z.optional(z.boolean())
});

export const zChatCompletionDeleted = z.object({
    object: z.enum(['chat.completion.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

/**
 * Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
 *
 */
export const zChatCompletionFunctionCallOption = z.object({
    name: z.string()
});

export const zChatCompletionMessageToolCall = z.object({
    id: z.string(),
    type: z.enum(['function']),
    function: z.object({
        name: z.string(),
        arguments: z.string()
    })
});

export const zChatCompletionMessageToolCallChunk = z.object({
    index: z.int(),
    id: z.optional(z.string()),
    type: z.optional(z.enum(['function'])),
    function: z.optional(z.object({
        name: z.optional(z.string()),
        arguments: z.optional(z.string())
    }))
});

/**
 * The tool calls generated by the model, such as function calls.
 */
export const zChatCompletionMessageToolCalls = z.array(zChatCompletionMessageToolCall);

/**
 * Output types that you would like the model to generate for this request.
 * Most models are capable of generating text, which is the default:
 *
 * `["text"]`
 *
 * The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
 * request that this model generate both text and audio responses, you can
 * use:
 *
 * `["text", "audio"]`
 *
 */
export const zChatCompletionModalities = z.union([
    z.array(z.enum(['text', 'audio'])),
    z.null()
]);

/**
 * Specifies a tool the model should use. Use to force the model to call a specific function.
 */
export const zChatCompletionNamedToolChoice = z.object({
    type: z.enum(['function']),
    function: z.object({
        name: z.string()
    })
});

/**
 * Function message
 *
 * @deprecated
 */
export const zChatCompletionRequestFunctionMessage = z.object({
    role: z.enum(['function']),
    content: z.union([
        z.string(),
        z.null()
    ]),
    name: z.string()
});

/**
 * Audio content part
 *
 * Learn about [audio inputs](/docs/guides/audio).
 *
 */
export const zChatCompletionRequestMessageContentPartAudio = z.object({
    type: z.enum(['input_audio']),
    input_audio: z.object({
        data: z.string(),
        format: z.enum(['wav', 'mp3'])
    })
});

/**
 * File content part
 *
 * Learn about [file inputs](/docs/guides/text) for text generation.
 *
 */
export const zChatCompletionRequestMessageContentPartFile = z.object({
    type: z.enum(['file']),
    file: z.object({
        filename: z.optional(z.string()),
        file_data: z.optional(z.string()),
        file_id: z.optional(z.string())
    })
});

/**
 * Image content part
 *
 * Learn about [image inputs](/docs/guides/vision).
 *
 */
export const zChatCompletionRequestMessageContentPartImage = z.object({
    type: z.enum(['image_url']),
    image_url: z.object({
        url: z.url(),
        detail: z.optional(z.enum([
            'auto',
            'low',
            'high'
        ]))
    })
});

/**
 * Refusal content part
 */
export const zChatCompletionRequestMessageContentPartRefusal = z.object({
    type: z.enum(['refusal']),
    refusal: z.string()
});

/**
 * Text content part
 *
 * Learn about [text inputs](/docs/guides/text-generation).
 *
 */
export const zChatCompletionRequestMessageContentPartText = z.object({
    type: z.enum(['text']),
    text: z.string()
});

export const zChatCompletionRequestAssistantMessageContentPart = z.union([
    zChatCompletionRequestMessageContentPartText,
    zChatCompletionRequestMessageContentPartRefusal
]);

/**
 * Assistant message
 *
 * Messages sent by the model in response to user messages.
 *
 */
export const zChatCompletionRequestAssistantMessage = z.object({
    content: z.optional(z.union([
        z.string(),
        z.array(zChatCompletionRequestAssistantMessageContentPart).min(1),
        z.null()
    ])),
    refusal: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    role: z.enum(['assistant']),
    name: z.optional(z.string()),
    audio: z.optional(z.union([
        z.object({
            id: z.string()
        }),
        z.null()
    ])),
    tool_calls: z.optional(zChatCompletionMessageToolCalls),
    function_call: z.optional(z.union([
        z.object({
            arguments: z.string(),
            name: z.string()
        }),
        z.null()
    ]))
});

/**
 * Developer message
 *
 * Developer-provided instructions that the model should follow, regardless of
 * messages sent by the user. With o1 models and newer, `developer` messages
 * replace the previous `system` messages.
 *
 */
export const zChatCompletionRequestDeveloperMessage = z.object({
    content: z.union([
        z.string(),
        z.array(zChatCompletionRequestMessageContentPartText).min(1)
    ]),
    role: z.enum(['developer']),
    name: z.optional(z.string())
});

export const zChatCompletionRequestSystemMessageContentPart = zChatCompletionRequestMessageContentPartText;

/**
 * System message
 *
 * Developer-provided instructions that the model should follow, regardless of
 * messages sent by the user. With o1 models and newer, use `developer` messages
 * for this purpose instead.
 *
 */
export const zChatCompletionRequestSystemMessage = z.object({
    content: z.union([
        z.string(),
        z.array(zChatCompletionRequestSystemMessageContentPart).min(1)
    ]),
    role: z.enum(['system']),
    name: z.optional(z.string())
});

export const zChatCompletionRequestToolMessageContentPart = zChatCompletionRequestMessageContentPartText;

/**
 * Tool message
 */
export const zChatCompletionRequestToolMessage = z.object({
    role: z.enum(['tool']),
    content: z.union([
        z.string(),
        z.array(zChatCompletionRequestToolMessageContentPart).min(1)
    ]),
    tool_call_id: z.string()
});

export const zChatCompletionRequestUserMessageContentPart = z.union([
    zChatCompletionRequestMessageContentPartText,
    zChatCompletionRequestMessageContentPartImage,
    zChatCompletionRequestMessageContentPartAudio,
    zChatCompletionRequestMessageContentPartFile
]);

/**
 * User message
 *
 * Messages sent by an end user, containing prompts or additional context
 * information.
 *
 */
export const zChatCompletionRequestUserMessage = z.object({
    content: z.union([
        z.string(),
        z.array(zChatCompletionRequestUserMessageContentPart).min(1)
    ]),
    role: z.enum(['user']),
    name: z.optional(z.string())
});

export const zChatCompletionRequestMessage = z.union([
    zChatCompletionRequestDeveloperMessage,
    zChatCompletionRequestSystemMessage,
    zChatCompletionRequestUserMessage,
    zChatCompletionRequestAssistantMessage,
    zChatCompletionRequestToolMessage,
    zChatCompletionRequestFunctionMessage
]);

/**
 * A chat completion message generated by the model.
 */
export const zChatCompletionResponseMessage = z.object({
    content: z.union([
        z.string(),
        z.null()
    ]),
    refusal: z.union([
        z.string(),
        z.null()
    ]),
    tool_calls: z.optional(zChatCompletionMessageToolCalls),
    annotations: z.optional(z.array(z.object({
        type: z.enum(['url_citation']),
        url_citation: z.object({
            end_index: z.int(),
            start_index: z.int(),
            url: z.string(),
            title: z.string()
        })
    }))),
    role: z.enum(['assistant']),
    function_call: z.optional(z.object({
        arguments: z.string(),
        name: z.string()
    })),
    audio: z.optional(z.union([
        z.object({
            id: z.string(),
            expires_at: z.int(),
            data: z.string(),
            transcript: z.string()
        }),
        z.null()
    ]))
});

/**
 * ChatCompletionMessageList
 *
 * An object representing a list of chat completion messages.
 *
 */
export const zChatCompletionMessageList = z.object({
    object: z.enum(['list']),
    data: z.array(zChatCompletionResponseMessage.and(z.object({
        id: z.string()
    }))),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * The role of the author of a message
 */
export const zChatCompletionRole = z.enum([
    'developer',
    'system',
    'user',
    'assistant',
    'tool',
    'function'
]);

/**
 * Options for streaming response. Only set this when you set `stream: true`.
 *
 */
export const zChatCompletionStreamOptions = z.union([
    z.object({
        include_usage: z.optional(z.boolean())
    }),
    z.null()
]).default(null);

/**
 * A chat completion delta generated by streamed model responses.
 */
export const zChatCompletionStreamResponseDelta = z.object({
    content: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    function_call: z.optional(z.object({
        arguments: z.optional(z.string()),
        name: z.optional(z.string())
    })),
    tool_calls: z.optional(z.array(zChatCompletionMessageToolCallChunk)),
    role: z.optional(z.enum([
        'developer',
        'system',
        'user',
        'assistant',
        'tool'
    ])),
    refusal: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

export const zChatCompletionTokenLogprob = z.object({
    token: z.string(),
    logprob: z.number(),
    bytes: z.union([
        z.array(z.int()),
        z.null()
    ]),
    top_logprobs: z.array(z.object({
        token: z.string(),
        logprob: z.number(),
        bytes: z.union([
            z.array(z.int()),
            z.null()
        ])
    }))
});

/**
 * Controls which (if any) tool is called by the model.
 * `none` means the model will not call any tool and instead generates a message.
 * `auto` means the model can pick between generating a message or calling one or more tools.
 * `required` means the model must call one or more tools.
 * Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
 *
 * `none` is the default when no tools are present. `auto` is the default if tools are present.
 *
 */
export const zChatCompletionToolChoiceOption = z.union([
    z.literal('none'),
    z.literal('auto'),
    z.literal('required'),
    zChatCompletionNamedToolChoice
]);

/**
 * Click
 *
 * A click action.
 *
 */
export const zClick = z.object({
    type: z.enum(['click']),
    button: z.enum([
        'left',
        'right',
        'wheel',
        'back',
        'forward'
    ]),
    x: z.int(),
    y: z.int()
});

/**
 * Code interpreter file output
 *
 * The output of a code interpreter tool call that is a file.
 *
 */
export const zCodeInterpreterFileOutput = z.object({
    type: z.enum(['files']),
    files: z.array(z.object({
        mime_type: z.string(),
        file_id: z.string()
    }))
});

/**
 * Code interpreter text output
 *
 * The output of a code interpreter tool call that is text.
 *
 */
export const zCodeInterpreterTextOutput = z.object({
    type: z.enum(['logs']),
    logs: z.string()
});

export const zCodeInterpreterToolOutput = z.union([
    zCodeInterpreterTextOutput,
    zCodeInterpreterFileOutput
]);

/**
 * Code interpreter tool call
 *
 * A tool call to run code.
 *
 */
export const zCodeInterpreterToolCall = z.object({
    id: z.string(),
    type: z.enum(['code_interpreter_call']),
    code: z.string(),
    status: z.enum([
        'in_progress',
        'interpreting',
        'completed'
    ]),
    results: z.array(zCodeInterpreterToolOutput)
});

/**
 * Comparison Filter
 *
 * A filter used to compare a specified attribute key to a given value using a defined comparison operation.
 *
 */
export const zComparisonFilter = z.object({
    type: z.enum([
        'eq',
        'ne',
        'gt',
        'gte',
        'lt',
        'lte'
    ]),
    key: z.string(),
    value: z.union([
        z.string(),
        z.number(),
        z.boolean()
    ])
});

export const zCompleteUploadRequest = z.object({
    part_ids: z.array(z.string()),
    md5: z.optional(z.string())
});

/**
 * Usage statistics for the completion request.
 */
export const zCompletionUsage = z.object({
    completion_tokens: z.int().default(0),
    prompt_tokens: z.int().default(0),
    total_tokens: z.int().default(0),
    completion_tokens_details: z.optional(z.object({
        accepted_prediction_tokens: z.optional(z.int()).default(0),
        audio_tokens: z.optional(z.int()).default(0),
        reasoning_tokens: z.optional(z.int()).default(0),
        rejected_prediction_tokens: z.optional(z.int()).default(0)
    })),
    prompt_tokens_details: z.optional(z.object({
        audio_tokens: z.optional(z.int()).default(0),
        cached_tokens: z.optional(z.int()).default(0)
    }))
});

/**
 * Compound Filter
 *
 * Combine multiple filters using `and` or `or`.
 */
export const zCompoundFilter = z.object({
    type: z.enum(['and', 'or']),
    filters: z.array(z.union([zComparisonFilter, z.unknown()]))
});

/**
 * A computer screenshot image used with the computer use tool.
 *
 */
export const zComputerScreenshotImage = z.object({
    type: z.enum(['computer_screenshot']),
    image_url: z.optional(z.string()),
    file_id: z.optional(z.string())
});

/**
 * A pending safety check for the computer call.
 *
 */
export const zComputerToolCallSafetyCheck = z.object({
    id: z.string(),
    code: z.string(),
    message: z.string()
});

/**
 * Computer tool call output
 *
 * The output of a computer tool call.
 *
 */
export const zComputerToolCallOutput = z.object({
    type: z.enum(['computer_call_output']),
    id: z.optional(z.string()),
    call_id: z.string(),
    acknowledged_safety_checks: z.optional(z.array(zComputerToolCallSafetyCheck)),
    output: zComputerScreenshotImage,
    status: z.optional(z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ]))
});

export const zComputerToolCallOutputResource = zComputerToolCallOutput.and(z.object({
    id: z.string()
}));

/**
 * Coordinate
 *
 * An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.
 *
 */
export const zCoordinate = z.object({
    x: z.int(),
    y: z.int()
});

/**
 * The aggregated costs details of the specific time bucket.
 */
export const zCostsResult = z.object({
    object: z.enum(['organization.costs.result']),
    amount: z.optional(z.object({
        value: z.optional(z.number()),
        currency: z.optional(z.string())
    })),
    line_item: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
 *
 */
export const zCreateCompletionResponse = z.object({
    id: z.string(),
    choices: z.array(z.object({
        finish_reason: z.enum([
            'stop',
            'length',
            'content_filter'
        ]),
        index: z.int(),
        logprobs: z.union([
            z.object({
                text_offset: z.optional(z.array(z.int())),
                token_logprobs: z.optional(z.array(z.number())),
                tokens: z.optional(z.array(z.string())),
                top_logprobs: z.optional(z.array(z.record(z.string(), z.number())))
            }),
            z.null()
        ]),
        text: z.string()
    })),
    created: z.int(),
    model: z.string(),
    system_fingerprint: z.optional(z.string()),
    object: z.enum(['text_completion']),
    usage: z.optional(zCompletionUsage)
});

export const zCreateEmbeddingRequest = z.object({
    input: z.union([
        z.string().default(''),
        z.array(z.string().default('')).min(1).max(2048),
        z.array(z.int()).min(1).max(2048),
        z.array(z.array(z.int()).min(1)).min(1).max(2048)
    ]),
    model: z.union([
        z.string(),
        z.enum([
            'text-embedding-ada-002',
            'text-embedding-3-small',
            'text-embedding-3-large'
        ])
    ]),
    encoding_format: z.optional(z.enum(['float', 'base64'])),
    dimensions: z.optional(z.int().gte(1)),
    user: z.optional(z.string())
});

/**
 * CustomDataSourceConfig
 *
 * A CustomDataSourceConfig object that defines the schema for the data source used for the evaluation runs.
 * This schema is used to define the shape of the data that will be:
 * - Used to define your testing criteria and
 * - What data is required when creating a run
 *
 */
export const zCreateEvalCustomDataSourceConfig = z.object({
    type: z.enum(['custom']),
    item_schema: z.record(z.string(), z.unknown()),
    include_sample_schema: z.optional(z.boolean()).default(false)
});

/**
 * LogsDataSourceConfig
 *
 * A data source config which specifies the metadata property of your stored completions query.
 * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.
 *
 */
export const zCreateEvalLogsDataSourceConfig = z.object({
    type: z.enum(['logs']),
    metadata: z.optional(z.record(z.string(), z.unknown()))
});

export const zCreateFileRequest = z.object({
    file: z.string(),
    purpose: z.enum([
        'assistants',
        'batch',
        'fine-tune',
        'vision',
        'user_data',
        'evals'
    ])
});

export const zCreateFineTuningCheckpointPermissionRequest = z.object({
    project_ids: z.array(z.string())
});

export const zCreateImageEditRequest = z.object({
    image: z.union([
        z.string(),
        z.array(z.string()).max(16)
    ]),
    prompt: z.string(),
    mask: z.optional(z.string()),
    model: z.optional(z.union([
        z.string(),
        z.enum(['dall-e-2', 'gpt-image-1']),
        z.null()
    ])),
    n: z.optional(z.union([
        z.int().gte(1).lte(10).default(1),
        z.null()
    ])).default(1),
    size: z.optional(z.enum([
        '256x256',
        '512x512',
        '1024x1024',
        '1536x1024',
        '1024x1536',
        'auto'
    ])),
    response_format: z.optional(z.enum(['url', 'b64_json'])),
    user: z.optional(z.string()),
    quality: z.optional(z.enum([
        'standard',
        'low',
        'medium',
        'high',
        'auto'
    ]))
});

export const zCreateImageRequest = z.object({
    prompt: z.string(),
    model: z.optional(z.union([
        z.string(),
        z.enum([
            'dall-e-2',
            'dall-e-3',
            'gpt-image-1'
        ]),
        z.null()
    ])),
    n: z.optional(z.union([
        z.int().gte(1).lte(10).default(1),
        z.null()
    ])).default(1),
    quality: z.optional(z.enum([
        'standard',
        'hd',
        'low',
        'medium',
        'high',
        'auto'
    ])),
    response_format: z.optional(z.enum(['url', 'b64_json'])),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    output_compression: z.optional(z.union([
        z.int().default(100),
        z.null()
    ])).default(100),
    size: z.optional(z.enum([
        'auto',
        '1024x1024',
        '1536x1024',
        '1024x1536',
        '256x256',
        '512x512',
        '1792x1024',
        '1024x1792'
    ])),
    moderation: z.optional(z.enum(['low', 'auto'])),
    background: z.optional(z.enum([
        'transparent',
        'opaque',
        'auto'
    ])),
    style: z.optional(z.enum(['vivid', 'natural'])),
    user: z.optional(z.string())
});

export const zCreateImageVariationRequest = z.object({
    image: z.string(),
    model: z.optional(z.union([
        z.string(),
        z.enum(['dall-e-2']),
        z.null()
    ])),
    n: z.optional(z.union([
        z.int().gte(1).lte(10).default(1),
        z.null()
    ])).default(1),
    response_format: z.optional(z.enum(['url', 'b64_json'])),
    size: z.optional(z.enum([
        '256x256',
        '512x512',
        '1024x1024'
    ])),
    user: z.optional(z.string())
});

export const zCreateModerationRequest = z.object({
    input: z.union([
        z.string().default(''),
        z.array(z.string().default('')),
        z.array(z.union([z.object({
                type: z.enum(['image_url']),
                image_url: z.object({
                    url: z.url()
                })
            }), z.object({
                type: z.enum(['text']),
                text: z.string()
            })]))
    ]),
    model: z.optional(z.union([
        z.string(),
        z.enum([
            'omni-moderation-latest',
            'omni-moderation-2024-09-26',
            'text-moderation-latest',
            'text-moderation-stable'
        ])
    ]))
});

/**
 * Represents if a given text input is potentially harmful.
 */
export const zCreateModerationResponse = z.object({
    id: z.string(),
    model: z.string(),
    results: z.array(z.object({
        flagged: z.boolean(),
        categories: z.object({
            hate: z.boolean(),
            'hate/threatening': z.boolean(),
            harassment: z.boolean(),
            'harassment/threatening': z.boolean(),
            illicit: z.union([
                z.boolean(),
                z.null()
            ]),
            'illicit/violent': z.union([
                z.boolean(),
                z.null()
            ]),
            'self-harm': z.boolean(),
            'self-harm/intent': z.boolean(),
            'self-harm/instructions': z.boolean(),
            sexual: z.boolean(),
            'sexual/minors': z.boolean(),
            violence: z.boolean(),
            'violence/graphic': z.boolean()
        }),
        category_scores: z.object({
            hate: z.number(),
            'hate/threatening': z.number(),
            harassment: z.number(),
            'harassment/threatening': z.number(),
            illicit: z.number(),
            'illicit/violent': z.number(),
            'self-harm': z.number(),
            'self-harm/intent': z.number(),
            'self-harm/instructions': z.number(),
            sexual: z.number(),
            'sexual/minors': z.number(),
            violence: z.number(),
            'violence/graphic': z.number()
        }),
        category_applied_input_types: z.object({
            hate: z.array(z.enum(['text'])),
            'hate/threatening': z.array(z.enum(['text'])),
            harassment: z.array(z.enum(['text'])),
            'harassment/threatening': z.array(z.enum(['text'])),
            illicit: z.array(z.enum(['text'])),
            'illicit/violent': z.array(z.enum(['text'])),
            'self-harm': z.array(z.enum(['text', 'image'])),
            'self-harm/intent': z.array(z.enum(['text', 'image'])),
            'self-harm/instructions': z.array(z.enum(['text', 'image'])),
            sexual: z.array(z.enum(['text', 'image'])),
            'sexual/minors': z.array(z.enum(['text'])),
            violence: z.array(z.enum(['text', 'image'])),
            'violence/graphic': z.array(z.enum(['text', 'image']))
        })
    }))
});

/**
 * Represents a transcription response returned by model, based on the provided input.
 */
export const zCreateTranscriptionResponseJson = z.object({
    text: z.string(),
    logprobs: z.optional(z.array(z.object({
        token: z.optional(z.string()),
        logprob: z.optional(z.number()),
        bytes: z.optional(z.array(z.number()))
    })))
});

export const zCreateTranslationRequest = z.object({
    file: z.string(),
    model: z.union([
        z.string(),
        z.enum(['whisper-1'])
    ]),
    prompt: z.optional(z.string()),
    response_format: z.optional(z.enum([
        'json',
        'text',
        'srt',
        'verbose_json',
        'vtt'
    ])),
    temperature: z.optional(z.number()).default(0)
});

export const zCreateTranslationResponseJson = z.object({
    text: z.string()
});

export const zCreateUploadRequest = z.object({
    filename: z.string(),
    purpose: z.enum([
        'assistants',
        'batch',
        'fine-tune',
        'vision'
    ]),
    bytes: z.int(),
    mime_type: z.string()
});

export const zDeleteAssistantResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.enum(['assistant.deleted'])
});

export const zDeleteCertificateResponse = z.object({
    object: z.enum(['certificate.deleted']),
    id: z.string()
});

export const zDeleteFileResponse = z.object({
    id: z.string(),
    object: z.enum(['file']),
    deleted: z.boolean()
});

export const zDeleteFineTuningCheckpointPermissionResponse = z.object({
    id: z.string(),
    object: z.enum(['checkpoint.permission']),
    deleted: z.boolean()
});

export const zDeleteMessageResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.enum(['thread.message.deleted'])
});

export const zDeleteModelResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.string()
});

export const zDeleteThreadResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.enum(['thread.deleted'])
});

export const zDeleteVectorStoreFileResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.enum(['vector_store.file.deleted'])
});

export const zDeleteVectorStoreResponse = z.object({
    id: z.string(),
    deleted: z.boolean(),
    object: z.enum(['vector_store.deleted'])
});

/**
 * Occurs when a stream ends.
 */
export const zDoneEvent = z.object({
    event: z.enum(['done']),
    data: z.enum(['[DONE]'])
});

/**
 * DoubleClick
 *
 * A double click action.
 *
 */
export const zDoubleClick = z.object({
    type: z.enum(['double_click']),
    x: z.int(),
    y: z.int()
});

/**
 * Drag
 *
 * A drag action.
 *
 */
export const zDrag = z.object({
    type: z.enum(['drag']),
    path: z.array(zCoordinate)
});

/**
 * Represents an embedding vector returned by embedding endpoint.
 *
 */
export const zEmbedding = z.object({
    index: z.int(),
    embedding: z.array(z.number()),
    object: z.enum(['embedding'])
});

export const zCreateEmbeddingResponse = z.object({
    data: z.array(zEmbedding),
    model: z.string(),
    object: z.enum(['list']),
    usage: z.object({
        prompt_tokens: z.int(),
        total_tokens: z.int()
    })
});

export const zError = z.object({
    code: z.union([
        z.string(),
        z.null()
    ]),
    message: z.string(),
    param: z.union([
        z.string(),
        z.null()
    ]),
    type: z.string()
});

/**
 * Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.
 */
export const zErrorEvent = z.object({
    event: z.enum(['error']),
    data: zError
});

export const zErrorResponse = z.object({
    error: zError
});

/**
 * EvalApiError
 *
 * An object representing an error response from the Eval API.
 *
 */
export const zEvalApiError = z.object({
    code: z.string(),
    message: z.string()
});

/**
 * CustomDataSourceConfig
 *
 * A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.
 * The response schema defines the shape of the data that will be:
 * - Used to define your testing criteria and
 * - What data is required when creating a run
 *
 */
export const zEvalCustomDataSourceConfig = z.object({
    type: z.enum(['custom']),
    schema: z.record(z.string(), z.unknown())
});

/**
 * EvalJsonlFileContentSource
 */
export const zEvalJsonlFileContentSource = z.object({
    type: z.enum(['file_content']),
    content: z.array(z.object({
        item: z.record(z.string(), z.unknown()),
        sample: z.optional(z.record(z.string(), z.unknown()))
    }))
});

/**
 * EvalJsonlFileIdSource
 */
export const zEvalJsonlFileIdSource = z.object({
    type: z.enum(['file_id']),
    id: z.string()
});

/**
 * JsonlRunDataSource
 *
 * A JsonlRunDataSource object with that specifies a JSONL file that matches the eval
 *
 */
export const zCreateEvalJsonlRunDataSource = z.object({
    type: z.enum(['jsonl']),
    source: z.union([
        zEvalJsonlFileContentSource,
        zEvalJsonlFileIdSource
    ])
});

/**
 * PythonGrader
 *
 * A PythonGrader object that runs a python script on the input.
 *
 */
export const zEvalPythonGrader = z.object({
    type: z.enum(['python']),
    name: z.string(),
    source: z.string(),
    pass_threshold: z.optional(z.number()),
    image_tag: z.optional(z.string())
});

/**
 * EvalRunOutputItem
 *
 * A schema representing an evaluation run output item.
 *
 */
export const zEvalRunOutputItem = z.object({
    object: z.enum(['eval.run.output_item']),
    id: z.string(),
    run_id: z.string(),
    eval_id: z.string(),
    created_at: z.int(),
    status: z.string(),
    datasource_item_id: z.int(),
    datasource_item: z.record(z.string(), z.unknown()),
    results: z.array(z.record(z.string(), z.unknown())),
    sample: z.object({
        input: z.array(z.object({
            role: z.string(),
            content: z.string()
        })),
        output: z.array(z.object({
            role: z.optional(z.string()),
            content: z.optional(z.string())
        })),
        finish_reason: z.string(),
        model: z.string(),
        usage: z.object({
            total_tokens: z.int(),
            completion_tokens: z.int(),
            prompt_tokens: z.int(),
            cached_tokens: z.int()
        }),
        error: zEvalApiError,
        temperature: z.number(),
        max_completion_tokens: z.int(),
        top_p: z.number(),
        seed: z.int()
    })
});

/**
 * EvalRunOutputItemList
 *
 * An object representing a list of output items for an evaluation run.
 *
 */
export const zEvalRunOutputItemList = z.object({
    object: z.enum(['list']),
    data: z.array(zEvalRunOutputItem),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * StringCheckGrader
 *
 * A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.
 *
 */
export const zEvalStringCheckGrader = z.object({
    type: z.enum(['string_check']),
    name: z.string(),
    input: z.string(),
    reference: z.string(),
    operation: z.enum([
        'eq',
        'ne',
        'like',
        'ilike'
    ])
});

/**
 * TextSimilarityGrader
 *
 * A TextSimilarityGrader object which grades text based on similarity metrics.
 *
 */
export const zEvalTextSimilarityGrader = z.object({
    type: z.enum(['text_similarity']),
    name: z.optional(z.string()),
    input: z.string(),
    reference: z.string(),
    pass_threshold: z.number(),
    evaluation_metric: z.enum([
        'fuzzy_match',
        'bleu',
        'gleu',
        'meteor',
        'rouge_1',
        'rouge_2',
        'rouge_3',
        'rouge_4',
        'rouge_5',
        'rouge_l'
    ])
});

/**
 * File path
 *
 * A path to a file.
 *
 */
export const zFilePath = z.object({
    type: z.enum(['file_path']),
    file_id: z.string(),
    index: z.int()
});

/**
 * The ranker to use for the file search. If not specified will use the `auto` ranker.
 */
export const zFileSearchRanker = z.enum(['auto', 'default_2024_08_21']);

/**
 * File search tool call ranking options
 *
 * The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.
 *
 * See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.
 *
 */
export const zFileSearchRankingOptions = z.object({
    ranker: z.optional(zFileSearchRanker),
    score_threshold: z.number().gte(0).lte(1)
});

/**
 * FileSearch tool
 */
export const zAssistantToolsFileSearch = z.object({
    type: z.enum(['file_search']),
    file_search: z.optional(z.object({
        max_num_results: z.optional(z.int().gte(1).lte(50)),
        ranking_options: z.optional(zFileSearchRankingOptions)
    }))
});

export const zFineTuneChatCompletionRequestAssistantMessage = z.object({
    weight: z.optional(z.union([z.literal(0), z.literal(1)]))
}).and(zChatCompletionRequestAssistantMessage);

/**
 * The per-line training example of a fine-tuning input file for completions models
 */
export const zFineTuneCompletionRequestInput = z.object({
    prompt: z.optional(z.string()),
    completion: z.optional(z.string())
});

/**
 * Configuration for the DPO fine-tuning method.
 */
export const zFineTuneDpoMethod = z.object({
    hyperparameters: z.optional(z.object({
        beta: z.optional(z.union([
            z.enum(['auto']),
            z.number().gt(0).lte(2)
        ])),
        batch_size: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(256)
        ])),
        learning_rate_multiplier: z.optional(z.union([
            z.enum(['auto']),
            z.number().gt(0)
        ])),
        n_epochs: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(50)
        ]))
    }))
});

/**
 * Configuration for the supervised fine-tuning method.
 */
export const zFineTuneSupervisedMethod = z.object({
    hyperparameters: z.optional(z.object({
        batch_size: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(256)
        ])),
        learning_rate_multiplier: z.optional(z.union([
            z.enum(['auto']),
            z.number().gt(0)
        ])),
        n_epochs: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(50)
        ]))
    }))
});

/**
 * The method used for fine-tuning.
 */
export const zFineTuneMethod = z.object({
    type: z.optional(z.enum(['supervised', 'dpo'])),
    supervised: z.optional(zFineTuneSupervisedMethod),
    dpo: z.optional(zFineTuneDpoMethod)
});

/**
 * FineTuningCheckpointPermission
 *
 * The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.
 *
 */
export const zFineTuningCheckpointPermission = z.object({
    id: z.string(),
    created_at: z.int(),
    project_id: z.string(),
    object: z.enum(['checkpoint.permission'])
});

/**
 * Fine-Tuning Job Integration
 */
export const zFineTuningIntegration = z.object({
    type: z.enum(['wandb']),
    wandb: z.object({
        project: z.string(),
        name: z.optional(z.union([
            z.string(),
            z.null()
        ])),
        entity: z.optional(z.union([
            z.string(),
            z.null()
        ])),
        tags: z.optional(z.array(z.string()))
    })
});

/**
 * FineTuningJobCheckpoint
 *
 * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
 *
 */
export const zFineTuningJobCheckpoint = z.object({
    id: z.string(),
    created_at: z.int(),
    fine_tuned_model_checkpoint: z.string(),
    step_number: z.int(),
    metrics: z.object({
        step: z.optional(z.number()),
        train_loss: z.optional(z.number()),
        train_mean_token_accuracy: z.optional(z.number()),
        valid_loss: z.optional(z.number()),
        valid_mean_token_accuracy: z.optional(z.number()),
        full_valid_loss: z.optional(z.number()),
        full_valid_mean_token_accuracy: z.optional(z.number())
    }),
    fine_tuning_job_id: z.string(),
    object: z.enum(['fine_tuning.job.checkpoint'])
});

/**
 * Fine-tuning job event object
 */
export const zFineTuningJobEvent = z.object({
    object: z.enum(['fine_tuning.job.event']),
    id: z.string(),
    created_at: z.int(),
    level: z.enum([
        'info',
        'warn',
        'error'
    ]),
    message: z.string(),
    type: z.optional(z.enum(['message', 'metrics'])),
    data: z.optional(z.record(z.string(), z.unknown()))
});

/**
 * The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
 *
 * Omitting `parameters` defines a function with an empty parameter list.
 */
export const zFunctionParameters = z.record(z.string(), z.unknown());

/**
 * @deprecated
 */
export const zChatCompletionFunctions = z.object({
    description: z.optional(z.string()),
    name: z.string(),
    parameters: z.optional(zFunctionParameters)
});

export const zFunctionObject = z.object({
    description: z.optional(z.string()),
    name: z.string(),
    parameters: z.optional(zFunctionParameters),
    strict: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false)
});

/**
 * Function tool
 */
export const zAssistantToolsFunction = z.object({
    type: z.enum(['function']),
    function: zFunctionObject
});

export const zChatCompletionTool = z.object({
    type: z.enum(['function']),
    function: zFunctionObject
});

/**
 * Function tool call
 *
 * A tool call to run a function. See the
 * [function calling guide](/docs/guides/function-calling) for more information.
 *
 */
export const zFunctionToolCall = z.object({
    id: z.optional(z.string()),
    type: z.enum(['function_call']),
    call_id: z.string(),
    name: z.string(),
    arguments: z.string(),
    status: z.optional(z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ]))
});

/**
 * Function tool call output
 *
 * The output of a function tool call.
 *
 */
export const zFunctionToolCallOutput = z.object({
    id: z.optional(z.string()),
    type: z.enum(['function_call_output']),
    call_id: z.string(),
    output: z.string(),
    status: z.optional(z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ]))
});

export const zFunctionToolCallOutputResource = zFunctionToolCallOutput.and(z.object({
    id: z.string()
}));

export const zFunctionToolCallResource = zFunctionToolCall.and(z.object({
    id: z.string()
}));

/**
 * Represents the content or the URL of an image generated by the OpenAI API.
 */
export const zImage = z.object({
    b64_json: z.optional(z.string()),
    url: z.optional(z.string()),
    revised_prompt: z.optional(z.string())
});

/**
 * Image generation response
 *
 * The response from the image generation endpoint.
 */
export const zImagesResponse = z.object({
    created: z.int(),
    data: z.optional(z.array(zImage)),
    usage: z.optional(z.object({
        total_tokens: z.int(),
        input_tokens: z.int(),
        output_tokens: z.int(),
        input_tokens_details: z.object({
            text_tokens: z.int(),
            image_tokens: z.int()
        })
    }))
});

/**
 * Specify additional output data to include in the model response. Currently
 * supported values are:
 * - `file_search_call.results`: Include the search results of
 * the file search tool call.
 * - `message.input_image.image_url`: Include image urls from the input message.
 * - `computer_call_output.output.image_url`: Include image urls from the computer call output.
 *
 */
export const zIncludable = z.enum([
    'file_search_call.results',
    'message.input_image.image_url',
    'computer_call_output.output.image_url'
]);

/**
 * Audio input
 *
 * An audio input to the model.
 *
 */
export const zInputAudio = z.object({
    type: z.enum(['input_audio']),
    data: z.string(),
    format: z.enum(['mp3', 'wav'])
});

/**
 * Represents an individual `invite` to the organization.
 */
export const zInvite = z.object({
    object: z.enum(['organization.invite']),
    id: z.string(),
    email: z.string(),
    role: z.enum(['owner', 'reader']),
    status: z.enum([
        'accepted',
        'expired',
        'pending'
    ]),
    invited_at: z.int(),
    expires_at: z.int(),
    accepted_at: z.optional(z.int()),
    projects: z.optional(z.array(z.object({
        id: z.optional(z.string()),
        role: z.optional(z.enum(['member', 'owner']))
    })))
});

export const zInviteDeleteResponse = z.object({
    object: z.enum(['organization.invite.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

export const zInviteListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zInvite),
    first_id: z.optional(z.string()),
    last_id: z.optional(z.string()),
    has_more: z.optional(z.boolean())
});

export const zInviteRequest = z.object({
    email: z.string(),
    role: z.enum(['reader', 'owner']),
    projects: z.optional(z.array(z.object({
        id: z.string(),
        role: z.enum(['member', 'owner'])
    })))
});

/**
 * KeyPress
 *
 * A collection of keypresses the model would like to perform.
 *
 */
export const zKeyPress = z.object({
    type: z.enum(['keypress']),
    keys: z.array(z.string())
});

export const zListAuditLogsResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zAuditLog),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zListCertificatesResponse = z.object({
    data: z.array(zCertificate),
    first_id: z.optional(z.string()),
    last_id: z.optional(z.string()),
    has_more: z.boolean(),
    object: z.enum(['list'])
});

export const zListFineTuningCheckpointPermissionResponse = z.object({
    data: z.array(zFineTuningCheckpointPermission),
    object: z.enum(['list']),
    first_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    last_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    has_more: z.boolean()
});

export const zListFineTuningJobCheckpointsResponse = z.object({
    data: z.array(zFineTuningJobCheckpoint),
    object: z.enum(['list']),
    first_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    last_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    has_more: z.boolean()
});

export const zListFineTuningJobEventsResponse = z.object({
    data: z.array(zFineTuningJobEvent),
    object: z.enum(['list']),
    has_more: z.boolean()
});

/**
 * A log probability object.
 *
 */
export const zLogProbProperties = z.object({
    token: z.string(),
    logprob: z.number(),
    bytes: z.array(z.int())
});

/**
 * Image file
 *
 * References an image [File](/docs/api-reference/files) in the content of a message.
 */
export const zMessageContentImageFileObject = z.object({
    type: z.enum(['image_file']),
    image_file: z.object({
        file_id: z.string(),
        detail: z.optional(z.enum([
            'auto',
            'low',
            'high'
        ]))
    })
});

/**
 * Image URL
 *
 * References an image URL in the content of a message.
 */
export const zMessageContentImageUrlObject = z.object({
    type: z.enum(['image_url']),
    image_url: z.object({
        url: z.url(),
        detail: z.optional(z.enum([
            'auto',
            'low',
            'high'
        ]))
    })
});

/**
 * Refusal
 *
 * The refusal content generated by the assistant.
 */
export const zMessageContentRefusalObject = z.object({
    type: z.enum(['refusal']),
    refusal: z.string()
});

/**
 * File citation
 *
 * A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
 */
export const zMessageContentTextAnnotationsFileCitationObject = z.object({
    type: z.enum(['file_citation']),
    text: z.string(),
    file_citation: z.object({
        file_id: z.string()
    }),
    start_index: z.int().gte(0),
    end_index: z.int().gte(0)
});

/**
 * File path
 *
 * A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
 */
export const zMessageContentTextAnnotationsFilePathObject = z.object({
    type: z.enum(['file_path']),
    text: z.string(),
    file_path: z.object({
        file_id: z.string()
    }),
    start_index: z.int().gte(0),
    end_index: z.int().gte(0)
});

/**
 * Text
 *
 * The text content that is part of a message.
 */
export const zMessageContentTextObject = z.object({
    type: z.enum(['text']),
    text: z.object({
        value: z.string(),
        annotations: z.array(z.union([zMessageContentTextAnnotationsFileCitationObject, zMessageContentTextAnnotationsFilePathObject]))
    })
});

/**
 * Image file
 *
 * References an image [File](/docs/api-reference/files) in the content of a message.
 */
export const zMessageDeltaContentImageFileObject = z.object({
    index: z.int(),
    type: z.enum(['image_file']),
    image_file: z.optional(z.object({
        file_id: z.optional(z.string()),
        detail: z.optional(z.enum([
            'auto',
            'low',
            'high'
        ]))
    }))
});

/**
 * Image URL
 *
 * References an image URL in the content of a message.
 */
export const zMessageDeltaContentImageUrlObject = z.object({
    index: z.int(),
    type: z.enum(['image_url']),
    image_url: z.optional(z.object({
        url: z.optional(z.string()),
        detail: z.optional(z.enum([
            'auto',
            'low',
            'high'
        ]))
    }))
});

/**
 * Refusal
 *
 * The refusal content that is part of a message.
 */
export const zMessageDeltaContentRefusalObject = z.object({
    index: z.int(),
    type: z.enum(['refusal']),
    refusal: z.optional(z.string())
});

/**
 * File citation
 *
 * A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
 */
export const zMessageDeltaContentTextAnnotationsFileCitationObject = z.object({
    index: z.int(),
    type: z.enum(['file_citation']),
    text: z.optional(z.string()),
    file_citation: z.optional(z.object({
        file_id: z.optional(z.string()),
        quote: z.optional(z.string())
    })),
    start_index: z.optional(z.int().gte(0)),
    end_index: z.optional(z.int().gte(0))
});

/**
 * File path
 *
 * A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
 */
export const zMessageDeltaContentTextAnnotationsFilePathObject = z.object({
    index: z.int(),
    type: z.enum(['file_path']),
    text: z.optional(z.string()),
    file_path: z.optional(z.object({
        file_id: z.optional(z.string())
    })),
    start_index: z.optional(z.int().gte(0)),
    end_index: z.optional(z.int().gte(0))
});

/**
 * Text
 *
 * The text content that is part of a message.
 */
export const zMessageDeltaContentTextObject = z.object({
    index: z.int(),
    type: z.enum(['text']),
    text: z.optional(z.object({
        value: z.optional(z.string()),
        annotations: z.optional(z.array(z.union([zMessageDeltaContentTextAnnotationsFileCitationObject, zMessageDeltaContentTextAnnotationsFilePathObject])))
    }))
});

/**
 * Message delta object
 *
 * Represents a message delta i.e. any changed fields on a message during streaming.
 *
 */
export const zMessageDeltaObject = z.object({
    id: z.string(),
    object: z.enum(['thread.message.delta']),
    delta: z.object({
        role: z.optional(z.enum(['user', 'assistant'])),
        content: z.optional(z.array(z.union([
            zMessageDeltaContentImageFileObject,
            zMessageDeltaContentTextObject,
            zMessageDeltaContentRefusalObject,
            zMessageDeltaContentImageUrlObject
        ])))
    })
});

/**
 * Text
 *
 * The text content that is part of a message.
 */
export const zMessageRequestContentTextObject = z.object({
    type: z.enum(['text']),
    text: z.string()
});

/**
 * Set of 16 key-value pairs that can be attached to an object. This can be
 * useful for storing additional information about the object in a structured
 * format, and querying for objects via API or the dashboard.
 *
 * Keys are strings with a maximum length of 64 characters. Values are strings
 * with a maximum length of 512 characters.
 *
 */
export const zMetadata = z.union([
    z.record(z.string(), z.string()),
    z.null()
]);

export const zBatch = z.object({
    id: z.string(),
    object: z.enum(['batch']),
    endpoint: z.string(),
    errors: z.optional(z.object({
        object: z.optional(z.string()),
        data: z.optional(z.array(z.object({
            code: z.optional(z.string()),
            message: z.optional(z.string()),
            param: z.optional(z.union([
                z.string(),
                z.null()
            ])),
            line: z.optional(z.union([
                z.int(),
                z.null()
            ]))
        })))
    })),
    input_file_id: z.string(),
    completion_window: z.string(),
    status: z.enum([
        'validating',
        'failed',
        'in_progress',
        'finalizing',
        'completed',
        'expired',
        'cancelling',
        'cancelled'
    ]),
    output_file_id: z.optional(z.string()),
    error_file_id: z.optional(z.string()),
    created_at: z.int(),
    in_progress_at: z.optional(z.int()),
    expires_at: z.optional(z.int()),
    finalizing_at: z.optional(z.int()),
    completed_at: z.optional(z.int()),
    failed_at: z.optional(z.int()),
    expired_at: z.optional(z.int()),
    cancelling_at: z.optional(z.int()),
    cancelled_at: z.optional(z.int()),
    request_counts: z.optional(z.object({
        total: z.int(),
        completed: z.int(),
        failed: z.int()
    })),
    metadata: z.optional(zMetadata)
});

export const zCreateFineTuningJobRequest = z.object({
    model: z.union([
        z.string(),
        z.enum([
            'babbage-002',
            'davinci-002',
            'gpt-3.5-turbo',
            'gpt-4o-mini'
        ])
    ]),
    training_file: z.string(),
    hyperparameters: z.optional(z.object({
        batch_size: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(256)
        ])),
        learning_rate_multiplier: z.optional(z.union([
            z.enum(['auto']),
            z.number().gt(0)
        ])),
        n_epochs: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(50)
        ]))
    })),
    suffix: z.optional(z.union([
        z.string().min(1).max(64),
        z.null()
    ])).default(null),
    validation_file: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    integrations: z.optional(z.union([
        z.array(z.object({
            type: z.enum(['wandb']),
            wandb: z.object({
                project: z.string(),
                name: z.optional(z.union([
                    z.string(),
                    z.null()
                ])),
                entity: z.optional(z.union([
                    z.string(),
                    z.null()
                ])),
                tags: z.optional(z.array(z.string()))
            })
        })),
        z.null()
    ])),
    seed: z.optional(z.union([
        z.int().gte(0).lte(2147483647),
        z.null()
    ])),
    method: z.optional(zFineTuneMethod),
    metadata: z.optional(zMetadata)
});

export const zCreateMessageRequest = z.object({
    role: z.enum(['user', 'assistant']),
    content: z.union([
        z.string(),
        z.array(z.union([
            zMessageContentImageFileObject,
            zMessageContentImageUrlObject,
            zMessageRequestContentTextObject
        ])).min(1)
    ]),
    attachments: z.optional(z.union([
        z.array(z.object({
            file_id: z.optional(z.string()),
            tools: z.optional(z.array(z.union([zAssistantToolsCode, zAssistantToolsFileSearchTypeOnly])))
        })),
        z.null()
    ])),
    metadata: z.optional(zMetadata)
});

/**
 * Options to create a new thread. If no thread is provided when running a
 * request, an empty thread will be created.
 *
 */
export const zCreateThreadRequest = z.object({
    messages: z.optional(z.array(zCreateMessageRequest)),
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.intersection(z.unknown(), z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1)),
                vector_stores: z.optional(z.array(z.object({
                    file_ids: z.optional(z.array(z.string()).max(10000)),
                    chunking_strategy: z.optional(z.union([
                        z.object({
                            type: z.enum(['auto'])
                        }),
                        z.object({
                            type: z.enum(['static']),
                            static: z.object({
                                max_chunk_size_tokens: z.int().gte(100).lte(4096),
                                chunk_overlap_tokens: z.int()
                            })
                        })
                    ])),
                    metadata: z.optional(zMetadata)
                })).max(1))
            })))
        }),
        z.null()
    ])),
    metadata: z.optional(zMetadata)
});

/**
 * StoredCompletionsDataSourceConfig
 *
 * A StoredCompletionsDataSourceConfig which specifies the metadata property of your stored completions query.
 * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.
 * The schema returned by this data source config is used to defined what variables are available in your evals.
 * `item` and `sample` are both defined when using this data source config.
 *
 */
export const zEvalStoredCompletionsDataSourceConfig = z.object({
    type: z.enum(['stored_completions']),
    metadata: z.optional(zMetadata),
    schema: z.record(z.string(), z.unknown())
});

/**
 * StoredCompletionsRunDataSource
 *
 * A StoredCompletionsRunDataSource configuration describing a set of filters
 *
 */
export const zEvalStoredCompletionsSource = z.object({
    type: z.enum(['stored_completions']),
    metadata: z.optional(zMetadata),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    created_after: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    created_before: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    limit: z.optional(z.union([
        z.int(),
        z.null()
    ]))
});

/**
 * FineTuningJob
 *
 * The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
 *
 */
export const zFineTuningJob = z.object({
    id: z.string(),
    created_at: z.int(),
    error: z.union([
        z.object({
            code: z.string(),
            message: z.string(),
            param: z.union([
                z.string(),
                z.null()
            ])
        }),
        z.null()
    ]),
    fine_tuned_model: z.union([
        z.string(),
        z.null()
    ]),
    finished_at: z.union([
        z.int(),
        z.null()
    ]),
    hyperparameters: z.object({
        batch_size: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(256)
        ])),
        learning_rate_multiplier: z.optional(z.union([
            z.enum(['auto']),
            z.number().gt(0)
        ])),
        n_epochs: z.optional(z.union([
            z.enum(['auto']),
            z.int().gte(1).lte(50)
        ]))
    }),
    model: z.string(),
    object: z.enum(['fine_tuning.job']),
    organization_id: z.string(),
    result_files: z.array(z.string()),
    status: z.enum([
        'validating_files',
        'queued',
        'running',
        'succeeded',
        'failed',
        'cancelled'
    ]),
    trained_tokens: z.union([
        z.int(),
        z.null()
    ]),
    training_file: z.string(),
    validation_file: z.union([
        z.string(),
        z.null()
    ]),
    integrations: z.optional(z.union([
        z.array(zFineTuningIntegration).max(5),
        z.null()
    ])),
    seed: z.int(),
    estimated_finish: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    method: z.optional(zFineTuneMethod),
    metadata: z.optional(zMetadata)
});

export const zListBatchesResponse = z.object({
    data: z.array(zBatch),
    first_id: z.optional(z.string()),
    last_id: z.optional(z.string()),
    has_more: z.boolean(),
    object: z.enum(['list'])
});

export const zListPaginatedFineTuningJobsResponse = z.object({
    data: z.array(zFineTuningJob),
    has_more: z.boolean(),
    object: z.enum(['list'])
});

/**
 * The message object
 *
 * Represents a message within a [thread](/docs/api-reference/threads).
 */
export const zMessageObject = z.object({
    id: z.string(),
    object: z.enum(['thread.message']),
    created_at: z.int(),
    thread_id: z.string(),
    status: z.enum([
        'in_progress',
        'incomplete',
        'completed'
    ]),
    incomplete_details: z.union([
        z.object({
            reason: z.enum([
                'content_filter',
                'max_tokens',
                'run_cancelled',
                'run_expired',
                'run_failed'
            ])
        }),
        z.null()
    ]),
    completed_at: z.union([
        z.int(),
        z.null()
    ]),
    incomplete_at: z.union([
        z.int(),
        z.null()
    ]),
    role: z.enum(['user', 'assistant']),
    content: z.array(z.union([
        zMessageContentImageFileObject,
        zMessageContentImageUrlObject,
        zMessageContentTextObject,
        zMessageContentRefusalObject
    ])),
    assistant_id: z.union([
        z.string(),
        z.null()
    ]),
    run_id: z.union([
        z.string(),
        z.null()
    ]),
    attachments: z.union([
        z.array(z.object({
            file_id: z.optional(z.string()),
            tools: z.optional(z.array(z.union([zAssistantToolsCode, zAssistantToolsFileSearchTypeOnly])))
        })),
        z.null()
    ]),
    metadata: zMetadata
});

export const zListMessagesResponse = z.object({
    object: z.string(),
    data: z.array(zMessageObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zMessageStreamEvent = z.union([
    z.object({
        event: z.enum(['thread.message.created']),
        data: zMessageObject
    }),
    z.object({
        event: z.enum(['thread.message.in_progress']),
        data: zMessageObject
    }),
    z.object({
        event: z.enum(['thread.message.delta']),
        data: zMessageDeltaObject
    }),
    z.object({
        event: z.enum(['thread.message.completed']),
        data: zMessageObject
    }),
    z.object({
        event: z.enum(['thread.message.incomplete']),
        data: zMessageObject
    })
]);

/**
 * Model
 *
 * Describes an OpenAI model offering that can be used with the API.
 */
export const zModel = z.object({
    id: z.string(),
    created: z.int(),
    object: z.enum(['model']),
    owned_by: z.string()
});

export const zListModelsResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zModel)
});

export const zModelIdsShared = z.union([
    z.string(),
    z.enum([
        'gpt-4.1',
        'gpt-4.1-mini',
        'gpt-4.1-nano',
        'gpt-4.1-2025-04-14',
        'gpt-4.1-mini-2025-04-14',
        'gpt-4.1-nano-2025-04-14',
        'o4-mini',
        'o4-mini-2025-04-16',
        'o3',
        'o3-2025-04-16',
        'o3-mini',
        'o3-mini-2025-01-31',
        'o1',
        'o1-2024-12-17',
        'o1-preview',
        'o1-preview-2024-09-12',
        'o1-mini',
        'o1-mini-2024-09-12',
        'gpt-4o',
        'gpt-4o-2024-11-20',
        'gpt-4o-2024-08-06',
        'gpt-4o-2024-05-13',
        'gpt-4o-audio-preview',
        'gpt-4o-audio-preview-2024-10-01',
        'gpt-4o-audio-preview-2024-12-17',
        'gpt-4o-mini-audio-preview',
        'gpt-4o-mini-audio-preview-2024-12-17',
        'gpt-4o-search-preview',
        'gpt-4o-mini-search-preview',
        'gpt-4o-search-preview-2025-03-11',
        'gpt-4o-mini-search-preview-2025-03-11',
        'chatgpt-4o-latest',
        'gpt-4o-mini',
        'gpt-4o-mini-2024-07-18',
        'gpt-4-turbo',
        'gpt-4-turbo-2024-04-09',
        'gpt-4-0125-preview',
        'gpt-4-turbo-preview',
        'gpt-4-1106-preview',
        'gpt-4-vision-preview',
        'gpt-4',
        'gpt-4-0314',
        'gpt-4-0613',
        'gpt-4-32k',
        'gpt-4-32k-0314',
        'gpt-4-32k-0613',
        'gpt-3.5-turbo',
        'gpt-3.5-turbo-16k',
        'gpt-3.5-turbo-0301',
        'gpt-3.5-turbo-0613',
        'gpt-3.5-turbo-1106',
        'gpt-3.5-turbo-0125',
        'gpt-3.5-turbo-16k-0613'
    ])
]);

export const zModelIdsResponses = z.union([
    zModelIdsShared,
    z.enum([
        'o1-pro',
        'o1-pro-2025-03-19',
        'computer-use-preview',
        'computer-use-preview-2025-03-11'
    ])
]);

export const zModelIds = z.union([
    zModelIdsShared,
    zModelIdsResponses
]);

export const zModifyCertificateRequest = z.object({
    name: z.string()
});

export const zModifyMessageRequest = z.object({
    metadata: z.optional(zMetadata)
});

export const zModifyRunRequest = z.object({
    metadata: z.optional(zMetadata)
});

export const zModifyThreadRequest = z.object({
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1))
            }))
        }),
        z.null()
    ])),
    metadata: z.optional(zMetadata)
});

/**
 * Move
 *
 * A mouse move action.
 *
 */
export const zMove = z.object({
    type: z.enum(['move']),
    x: z.int(),
    y: z.int()
});

/**
 * OpenAIFile
 *
 * The `File` object represents a document that has been uploaded to OpenAI.
 */
export const zOpenAiFile = z.object({
    id: z.string(),
    bytes: z.int(),
    created_at: z.int(),
    expires_at: z.optional(z.int()),
    filename: z.string(),
    object: z.enum(['file']),
    purpose: z.enum([
        'assistants',
        'assistants_output',
        'batch',
        'batch_output',
        'fine-tune',
        'fine-tune-results',
        'vision'
    ]),
    status: z.enum([
        'uploaded',
        'processed',
        'error'
    ]),
    status_details: z.optional(z.string())
});

export const zListFilesResponse = z.object({
    object: z.string(),
    data: z.array(zOpenAiFile),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Other Chunking Strategy
 *
 * This is returned when the chunking strategy is unknown. Typically, this is because the file was indexed before the `chunking_strategy` concept was introduced in the API.
 */
export const zOtherChunkingStrategyResponseParam = z.object({
    type: z.enum(['other'])
});

/**
 * Output audio
 *
 * An audio output from the model.
 *
 */
export const zOutputAudio = z.object({
    type: z.enum(['output_audio']),
    data: z.string(),
    transcript: z.string()
});

/**
 * Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.
 */
export const zParallelToolCalls = z.boolean().default(true);

/**
 * The per-line training example of a fine-tuning input file for chat models using the supervised method.
 */
export const zFineTuneChatRequestInput = z.object({
    messages: z.optional(z.array(z.union([
        zChatCompletionRequestSystemMessage,
        zChatCompletionRequestUserMessage,
        zFineTuneChatCompletionRequestAssistantMessage,
        zChatCompletionRequestToolMessage,
        zChatCompletionRequestFunctionMessage
    ])).min(1)),
    tools: z.optional(z.array(zChatCompletionTool)),
    parallel_tool_calls: z.optional(zParallelToolCalls),
    functions: z.optional(z.array(zChatCompletionFunctions).min(1).max(128))
});

/**
 * The per-line training example of a fine-tuning input file for chat models using the dpo method.
 */
export const zFineTunePreferenceRequestInput = z.object({
    input: z.optional(z.object({
        messages: z.optional(z.array(z.union([
            zChatCompletionRequestSystemMessage,
            zChatCompletionRequestUserMessage,
            zFineTuneChatCompletionRequestAssistantMessage,
            zChatCompletionRequestToolMessage,
            zChatCompletionRequestFunctionMessage
        ])).min(1)),
        tools: z.optional(z.array(zChatCompletionTool)),
        parallel_tool_calls: z.optional(zParallelToolCalls)
    })),
    preferred_completion: z.optional(z.array(zChatCompletionRequestAssistantMessage).max(1)),
    non_preferred_completion: z.optional(z.array(zChatCompletionRequestAssistantMessage).max(1))
});

/**
 * Static Content
 *
 * Static predicted output content, such as the content of a text file that is
 * being regenerated.
 *
 */
export const zPredictionContent = z.object({
    type: z.enum(['content']),
    content: z.union([
        z.string(),
        z.array(zChatCompletionRequestMessageContentPartText).min(1)
    ])
});

/**
 * Represents an individual project.
 */
export const zProject = z.object({
    id: z.string(),
    object: z.enum(['organization.project']),
    name: z.string(),
    created_at: z.int(),
    archived_at: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    status: z.enum(['active', 'archived'])
});

export const zProjectApiKeyDeleteResponse = z.object({
    object: z.enum(['organization.project.api_key.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

export const zProjectCreateRequest = z.object({
    name: z.string()
});

export const zProjectListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zProject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Represents a project rate limit config.
 */
export const zProjectRateLimit = z.object({
    object: z.enum(['project.rate_limit']),
    id: z.string(),
    model: z.string(),
    max_requests_per_1_minute: z.int(),
    max_tokens_per_1_minute: z.int(),
    max_images_per_1_minute: z.optional(z.int()),
    max_audio_megabytes_per_1_minute: z.optional(z.int()),
    max_requests_per_1_day: z.optional(z.int()),
    batch_1_day_max_input_tokens: z.optional(z.int())
});

export const zProjectRateLimitListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zProjectRateLimit),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zProjectRateLimitUpdateRequest = z.object({
    max_requests_per_1_minute: z.optional(z.int()),
    max_tokens_per_1_minute: z.optional(z.int()),
    max_images_per_1_minute: z.optional(z.int()),
    max_audio_megabytes_per_1_minute: z.optional(z.int()),
    max_requests_per_1_day: z.optional(z.int()),
    batch_1_day_max_input_tokens: z.optional(z.int())
});

/**
 * Represents an individual service account in a project.
 */
export const zProjectServiceAccount = z.object({
    object: z.enum(['organization.project.service_account']),
    id: z.string(),
    name: z.string(),
    role: z.enum(['owner', 'member']),
    created_at: z.int()
});

export const zProjectServiceAccountApiKey = z.object({
    object: z.enum(['organization.project.service_account.api_key']),
    value: z.string(),
    name: z.string(),
    created_at: z.int(),
    id: z.string()
});

export const zProjectServiceAccountCreateRequest = z.object({
    name: z.string()
});

export const zProjectServiceAccountCreateResponse = z.object({
    object: z.enum(['organization.project.service_account']),
    id: z.string(),
    name: z.string(),
    role: z.enum(['member']),
    created_at: z.int(),
    api_key: zProjectServiceAccountApiKey
});

export const zProjectServiceAccountDeleteResponse = z.object({
    object: z.enum(['organization.project.service_account.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

export const zProjectServiceAccountListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zProjectServiceAccount),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zProjectUpdateRequest = z.object({
    name: z.string()
});

/**
 * Represents an individual user in a project.
 */
export const zProjectUser = z.object({
    object: z.enum(['organization.project.user']),
    id: z.string(),
    name: z.string(),
    email: z.string(),
    role: z.enum(['owner', 'member']),
    added_at: z.int()
});

/**
 * Represents an individual API key in a project.
 */
export const zProjectApiKey = z.object({
    object: z.enum(['organization.project.api_key']),
    redacted_value: z.string(),
    name: z.string(),
    created_at: z.int(),
    last_used_at: z.int(),
    id: z.string(),
    owner: z.object({
        type: z.optional(z.enum(['user', 'service_account'])),
        user: z.optional(zProjectUser),
        service_account: z.optional(zProjectServiceAccount)
    })
});

export const zProjectApiKeyListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zProjectApiKey),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zProjectUserCreateRequest = z.object({
    user_id: z.string(),
    role: z.enum(['owner', 'member'])
});

export const zProjectUserDeleteResponse = z.object({
    object: z.enum(['organization.project.user.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

export const zProjectUserListResponse = z.object({
    object: z.string(),
    data: z.array(zProjectUser),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zProjectUserUpdateRequest = z.object({
    role: z.enum(['owner', 'member'])
});

/**
 * Send this event when you want to remove any item from the conversation
 * history. The server will respond with a `conversation.item.deleted` event,
 * unless the item does not exist in the conversation history, in which case the
 * server will respond with an error.
 *
 */
export const zRealtimeClientEventConversationItemDelete = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['conversation.item.delete']),
    item_id: z.string()
});

/**
 * Send this event when you want to retrieve the server's representation of a specific item in the conversation history. This is useful, for example, to inspect user audio after noise cancellation and VAD.
 * The server will respond with a `conversation.item.retrieved` event,
 * unless the item does not exist in the conversation history, in which case the
 * server will respond with an error.
 *
 */
export const zRealtimeClientEventConversationItemRetrieve = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['conversation.item.retrieve']),
    item_id: z.string()
});

/**
 * Send this event to truncate a previous assistant messages audio. The server
 * will produce audio faster than realtime, so this event is useful when the user
 * interrupts to truncate audio that has already been sent to the client but not
 * yet played. This will synchronize the server's understanding of the audio with
 * the client's playback.
 *
 * Truncating audio will delete the server-side text transcript to ensure there
 * is not text in the context that hasn't been heard by the user.
 *
 * If successful, the server will respond with a `conversation.item.truncated`
 * event.
 *
 */
export const zRealtimeClientEventConversationItemTruncate = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['conversation.item.truncate']),
    item_id: z.string(),
    content_index: z.int(),
    audio_end_ms: z.int()
});

/**
 * Send this event to append audio bytes to the input audio buffer. The audio
 * buffer is temporary storage you can write to and later commit. In Server VAD
 * mode, the audio buffer is used to detect speech and the server will decide
 * when to commit. When Server VAD is disabled, you must commit the audio buffer
 * manually.
 *
 * The client may choose how much audio to place in each event up to a maximum
 * of 15 MiB, for example streaming smaller chunks from the client may allow the
 * VAD to be more responsive. Unlike made other client events, the server will
 * not send a confirmation response to this event.
 *
 */
export const zRealtimeClientEventInputAudioBufferAppend = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['input_audio_buffer.append']),
    audio: z.string()
});

/**
 * Send this event to clear the audio bytes in the buffer. The server will
 * respond with an `input_audio_buffer.cleared` event.
 *
 */
export const zRealtimeClientEventInputAudioBufferClear = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['input_audio_buffer.clear'])
});

/**
 * Send this event to commit the user input audio buffer, which will create a
 * new user message item in the conversation. This event will produce an error
 * if the input audio buffer is empty. When in Server VAD mode, the client does
 * not need to send this event, the server will commit the audio buffer
 * automatically.
 *
 * Committing the input audio buffer will trigger input audio transcription
 * (if enabled in session configuration), but it will not create a response
 * from the model. The server will respond with an `input_audio_buffer.committed`
 * event.
 *
 */
export const zRealtimeClientEventInputAudioBufferCommit = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['input_audio_buffer.commit'])
});

/**
 * **WebRTC Only:** Emit to cut off the current audio response. This will trigger the server to
 * stop generating audio and emit a `output_audio_buffer.cleared` event. This
 * event should be preceded by a `response.cancel` client event to stop the
 * generation of the current response.
 * [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).
 *
 */
export const zRealtimeClientEventOutputAudioBufferClear = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['output_audio_buffer.clear'])
});

/**
 * Send this event to cancel an in-progress response. The server will respond
 * with a `response.cancelled` event or an error if there is no response to
 * cancel.
 *
 */
export const zRealtimeClientEventResponseCancel = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['response.cancel']),
    response_id: z.optional(z.string())
});

/**
 * The item to add to the conversation.
 */
export const zRealtimeConversationItem = z.object({
    id: z.optional(z.string()),
    type: z.optional(z.enum([
        'message',
        'function_call',
        'function_call_output'
    ])),
    object: z.optional(z.enum(['realtime.item'])),
    status: z.optional(z.enum(['completed', 'incomplete'])),
    role: z.optional(z.enum([
        'user',
        'assistant',
        'system'
    ])),
    content: z.optional(z.array(z.object({
        type: z.optional(z.enum([
            'input_audio',
            'input_text',
            'item_reference',
            'text'
        ])),
        text: z.optional(z.string()),
        id: z.optional(z.string()),
        audio: z.optional(z.string()),
        transcript: z.optional(z.string())
    }))),
    call_id: z.optional(z.string()),
    name: z.optional(z.string()),
    arguments: z.optional(z.string()),
    output: z.optional(z.string())
});

/**
 * Add a new Item to the Conversation's context, including messages, function
 * calls, and function call responses. This event can be used both to populate a
 * "history" of the conversation and to add new items mid-stream, but has the
 * current limitation that it cannot populate assistant audio messages.
 *
 * If successful, the server will respond with a `conversation.item.created`
 * event, otherwise an `error` event will be sent.
 *
 */
export const zRealtimeClientEventConversationItemCreate = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['conversation.item.create']),
    previous_item_id: z.optional(z.string()),
    item: zRealtimeConversationItem
});

/**
 * The item to add to the conversation.
 */
export const zRealtimeConversationItemWithReference = z.object({
    id: z.optional(z.string()),
    type: z.optional(z.enum([
        'message',
        'function_call',
        'function_call_output'
    ])),
    object: z.optional(z.enum(['realtime.item'])),
    status: z.optional(z.enum(['completed', 'incomplete'])),
    role: z.optional(z.enum([
        'user',
        'assistant',
        'system'
    ])),
    content: z.optional(z.array(z.object({
        type: z.optional(z.enum([
            'input_audio',
            'input_text',
            'item_reference',
            'text'
        ])),
        text: z.optional(z.string()),
        id: z.optional(z.string()),
        audio: z.optional(z.string()),
        transcript: z.optional(z.string())
    }))),
    call_id: z.optional(z.string()),
    name: z.optional(z.string()),
    arguments: z.optional(z.string()),
    output: z.optional(z.string())
});

/**
 * Returned when a conversation is created. Emitted right after session creation.
 *
 */
export const zRealtimeServerEventConversationCreated = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.created']),
    conversation: z.object({
        id: z.optional(z.string()),
        object: z.optional(z.string())
    })
});

/**
 * Returned when a conversation item is created. There are several scenarios that produce this event:
 * - The server is generating a Response, which if successful will produce
 * either one or two Items, which will be of type `message`
 * (role `assistant`) or type `function_call`.
 * - The input audio buffer has been committed, either by the client or the
 * server (in `server_vad` mode). The server will take the content of the
 * input audio buffer and add it to a new user message Item.
 * - The client has sent a `conversation.item.create` event to add a new Item
 * to the Conversation.
 *
 */
export const zRealtimeServerEventConversationItemCreated = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.created']),
    previous_item_id: z.string(),
    item: zRealtimeConversationItem
});

/**
 * Returned when an item in the conversation is deleted by the client with a
 * `conversation.item.delete` event. This event is used to synchronize the
 * server's understanding of the conversation history with the client's view.
 *
 */
export const zRealtimeServerEventConversationItemDeleted = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.deleted']),
    item_id: z.string()
});

/**
 * This event is the output of audio transcription for user audio written to the
 * user audio buffer. Transcription begins when the input audio buffer is
 * committed by the client or server (in `server_vad` mode). Transcription runs
 * asynchronously with Response creation, so this event may come before or after
 * the Response events.
 *
 * Realtime API models accept audio natively, and thus input transcription is a
 * separate process run on a separate ASR (Automatic Speech Recognition) model,
 * currently always `whisper-1`. Thus the transcript may diverge somewhat from
 * the model's interpretation, and should be treated as a rough guide.
 *
 */
export const zRealtimeServerEventConversationItemInputAudioTranscriptionCompleted = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.input_audio_transcription.completed']),
    item_id: z.string(),
    content_index: z.int(),
    transcript: z.string(),
    logprobs: z.optional(z.union([
        z.array(zLogProbProperties),
        z.null()
    ]))
});

/**
 * Returned when the text value of an input audio transcription content part is updated.
 *
 */
export const zRealtimeServerEventConversationItemInputAudioTranscriptionDelta = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.input_audio_transcription.delta']),
    item_id: z.string(),
    content_index: z.optional(z.int()),
    delta: z.optional(z.string()),
    logprobs: z.optional(z.union([
        z.array(zLogProbProperties),
        z.null()
    ]))
});

/**
 * Returned when input audio transcription is configured, and a transcription
 * request for a user message failed. These events are separate from other
 * `error` events so that the client can identify the related Item.
 *
 */
export const zRealtimeServerEventConversationItemInputAudioTranscriptionFailed = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.input_audio_transcription.failed']),
    item_id: z.string(),
    content_index: z.int(),
    error: z.object({
        type: z.optional(z.string()),
        code: z.optional(z.string()),
        message: z.optional(z.string()),
        param: z.optional(z.string())
    })
});

/**
 * Returned when a conversation item is retrieved with `conversation.item.retrieve`.
 *
 */
export const zRealtimeServerEventConversationItemRetrieved = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.retrieved']),
    item: zRealtimeConversationItem
});

/**
 * Returned when an earlier assistant audio message item is truncated by the
 * client with a `conversation.item.truncate` event. This event is used to
 * synchronize the server's understanding of the audio with the client's playback.
 *
 * This action will truncate the audio and remove the server-side text transcript
 * to ensure there is no text in the context that hasn't been heard by the user.
 *
 */
export const zRealtimeServerEventConversationItemTruncated = z.object({
    event_id: z.string(),
    type: z.enum(['conversation.item.truncated']),
    item_id: z.string(),
    content_index: z.int(),
    audio_end_ms: z.int()
});

/**
 * Returned when an error occurs, which could be a client problem or a server
 * problem. Most errors are recoverable and the session will stay open, we
 * recommend to implementors to monitor and log error messages by default.
 *
 */
export const zRealtimeServerEventError = z.object({
    event_id: z.string(),
    type: z.enum(['error']),
    error: z.object({
        type: z.string(),
        code: z.optional(z.union([
            z.string(),
            z.null()
        ])),
        message: z.string(),
        param: z.optional(z.union([
            z.string(),
            z.null()
        ])),
        event_id: z.optional(z.union([
            z.string(),
            z.null()
        ]))
    })
});

/**
 * Returned when the input audio buffer is cleared by the client with a
 * `input_audio_buffer.clear` event.
 *
 */
export const zRealtimeServerEventInputAudioBufferCleared = z.object({
    event_id: z.string(),
    type: z.enum(['input_audio_buffer.cleared'])
});

/**
 * Returned when an input audio buffer is committed, either by the client or
 * automatically in server VAD mode. The `item_id` property is the ID of the user
 * message item that will be created, thus a `conversation.item.created` event
 * will also be sent to the client.
 *
 */
export const zRealtimeServerEventInputAudioBufferCommitted = z.object({
    event_id: z.string(),
    type: z.enum(['input_audio_buffer.committed']),
    previous_item_id: z.string(),
    item_id: z.string()
});

/**
 * Sent by the server when in `server_vad` mode to indicate that speech has been
 * detected in the audio buffer. This can happen any time audio is added to the
 * buffer (unless speech is already detected). The client may want to use this
 * event to interrupt audio playback or provide visual feedback to the user.
 *
 * The client should expect to receive a `input_audio_buffer.speech_stopped` event
 * when speech stops. The `item_id` property is the ID of the user message item
 * that will be created when speech stops and will also be included in the
 * `input_audio_buffer.speech_stopped` event (unless the client manually commits
 * the audio buffer during VAD activation).
 *
 */
export const zRealtimeServerEventInputAudioBufferSpeechStarted = z.object({
    event_id: z.string(),
    type: z.enum(['input_audio_buffer.speech_started']),
    audio_start_ms: z.int(),
    item_id: z.string()
});

/**
 * Returned in `server_vad` mode when the server detects the end of speech in
 * the audio buffer. The server will also send an `conversation.item.created`
 * event with the user message item that is created from the audio buffer.
 *
 */
export const zRealtimeServerEventInputAudioBufferSpeechStopped = z.object({
    event_id: z.string(),
    type: z.enum(['input_audio_buffer.speech_stopped']),
    audio_end_ms: z.int(),
    item_id: z.string()
});

/**
 * **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD
 * mode when the user has interrupted (`input_audio_buffer.speech_started`),
 * or when the client has emitted the `output_audio_buffer.clear` event to manually
 * cut off the current audio response.
 * [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).
 *
 */
export const zRealtimeServerEventOutputAudioBufferCleared = z.object({
    event_id: z.string(),
    type: z.enum(['output_audio_buffer.cleared']),
    response_id: z.string()
});

/**
 * **WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is
 * emitted after an audio content part has been added (`response.content_part.added`)
 * to the response.
 * [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).
 *
 */
export const zRealtimeServerEventOutputAudioBufferStarted = z.object({
    event_id: z.string(),
    type: z.enum(['output_audio_buffer.started']),
    response_id: z.string()
});

/**
 * **WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server,
 * and no more audio is forthcoming. This event is emitted after the full response
 * data has been sent to the client (`response.done`).
 * [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).
 *
 */
export const zRealtimeServerEventOutputAudioBufferStopped = z.object({
    event_id: z.string(),
    type: z.enum(['output_audio_buffer.stopped']),
    response_id: z.string()
});

/**
 * Emitted at the beginning of a Response to indicate the updated rate limits.
 * When a Response is created some tokens will be "reserved" for the output
 * tokens, the rate limits shown here reflect that reservation, which is then
 * adjusted accordingly once the Response is completed.
 *
 */
export const zRealtimeServerEventRateLimitsUpdated = z.object({
    event_id: z.string(),
    type: z.enum(['rate_limits.updated']),
    rate_limits: z.array(z.object({
        name: z.optional(z.enum(['requests', 'tokens'])),
        limit: z.optional(z.int()),
        remaining: z.optional(z.int()),
        reset_seconds: z.optional(z.number())
    }))
});

/**
 * Returned when the model-generated audio is updated.
 */
export const zRealtimeServerEventResponseAudioDelta = z.object({
    event_id: z.string(),
    type: z.enum(['response.audio.delta']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    delta: z.string()
});

/**
 * Returned when the model-generated audio is done. Also emitted when a Response
 * is interrupted, incomplete, or cancelled.
 *
 */
export const zRealtimeServerEventResponseAudioDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.audio.done']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int()
});

/**
 * Returned when the model-generated transcription of audio output is updated.
 *
 */
export const zRealtimeServerEventResponseAudioTranscriptDelta = z.object({
    event_id: z.string(),
    type: z.enum(['response.audio_transcript.delta']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    delta: z.string()
});

/**
 * Returned when the model-generated transcription of audio output is done
 * streaming. Also emitted when a Response is interrupted, incomplete, or
 * cancelled.
 *
 */
export const zRealtimeServerEventResponseAudioTranscriptDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.audio_transcript.done']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    transcript: z.string()
});

/**
 * Returned when a new content part is added to an assistant message item during
 * response generation.
 *
 */
export const zRealtimeServerEventResponseContentPartAdded = z.object({
    event_id: z.string(),
    type: z.enum(['response.content_part.added']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    part: z.object({
        type: z.optional(z.enum(['audio', 'text'])),
        text: z.optional(z.string()),
        audio: z.optional(z.string()),
        transcript: z.optional(z.string())
    })
});

/**
 * Returned when a content part is done streaming in an assistant message item.
 * Also emitted when a Response is interrupted, incomplete, or cancelled.
 *
 */
export const zRealtimeServerEventResponseContentPartDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.content_part.done']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    part: z.object({
        type: z.optional(z.enum(['audio', 'text'])),
        text: z.optional(z.string()),
        audio: z.optional(z.string()),
        transcript: z.optional(z.string())
    })
});

/**
 * Returned when the model-generated function call arguments are updated.
 *
 */
export const zRealtimeServerEventResponseFunctionCallArgumentsDelta = z.object({
    event_id: z.string(),
    type: z.enum(['response.function_call_arguments.delta']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    call_id: z.string(),
    delta: z.string()
});

/**
 * Returned when the model-generated function call arguments are done streaming.
 * Also emitted when a Response is interrupted, incomplete, or cancelled.
 *
 */
export const zRealtimeServerEventResponseFunctionCallArgumentsDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.function_call_arguments.done']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    call_id: z.string(),
    arguments: z.string()
});

/**
 * Returned when a new Item is created during Response generation.
 */
export const zRealtimeServerEventResponseOutputItemAdded = z.object({
    event_id: z.string(),
    type: z.enum(['response.output_item.added']),
    response_id: z.string(),
    output_index: z.int(),
    item: zRealtimeConversationItem
});

/**
 * Returned when an Item is done streaming. Also emitted when a Response is
 * interrupted, incomplete, or cancelled.
 *
 */
export const zRealtimeServerEventResponseOutputItemDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.output_item.done']),
    response_id: z.string(),
    output_index: z.int(),
    item: zRealtimeConversationItem
});

/**
 * Returned when the text value of a "text" content part is updated.
 */
export const zRealtimeServerEventResponseTextDelta = z.object({
    event_id: z.string(),
    type: z.enum(['response.text.delta']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    delta: z.string()
});

/**
 * Returned when the text value of a "text" content part is done streaming. Also
 * emitted when a Response is interrupted, incomplete, or cancelled.
 *
 */
export const zRealtimeServerEventResponseTextDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.text.done']),
    response_id: z.string(),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    text: z.string()
});

/**
 * Realtime transcription session object configuration.
 */
export const zRealtimeTranscriptionSessionCreateRequest = z.object({
    modalities: z.optional(z.unknown()),
    input_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    input_audio_transcription: z.optional(z.object({
        model: z.optional(z.enum([
            'gpt-4o-transcribe',
            'gpt-4o-mini-transcribe',
            'whisper-1'
        ])),
        language: z.optional(z.string()),
        prompt: z.optional(z.string())
    })),
    turn_detection: z.optional(z.object({
        type: z.optional(z.enum(['server_vad', 'semantic_vad'])),
        eagerness: z.optional(z.enum([
            'low',
            'medium',
            'high',
            'auto'
        ])),
        threshold: z.optional(z.number()),
        prefix_padding_ms: z.optional(z.int()),
        silence_duration_ms: z.optional(z.int()),
        create_response: z.optional(z.boolean()).default(true),
        interrupt_response: z.optional(z.boolean()).default(true)
    })),
    input_audio_noise_reduction: z.optional(z.object({
        type: z.optional(z.enum(['near_field', 'far_field']))
    })).default(null),
    include: z.optional(z.array(z.string()))
});

/**
 * Send this event to update a transcription session.
 *
 */
export const zRealtimeClientEventTranscriptionSessionUpdate = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['transcription_session.update']),
    session: zRealtimeTranscriptionSessionCreateRequest
});

/**
 * A new Realtime transcription session configuration.
 *
 * When a session is created on the server via REST API, the session object
 * also contains an ephemeral key. Default TTL for keys is one minute. This
 * property is not present when a session is updated via the WebSocket API.
 *
 */
export const zRealtimeTranscriptionSessionCreateResponse = z.object({
    client_secret: z.object({
        value: z.string(),
        expires_at: z.int()
    }),
    modalities: z.optional(z.unknown()),
    input_audio_format: z.optional(z.string()),
    input_audio_transcription: z.optional(z.object({
        model: z.optional(z.enum([
            'gpt-4o-transcribe',
            'gpt-4o-mini-transcribe',
            'whisper-1'
        ])),
        language: z.optional(z.string()),
        prompt: z.optional(z.string())
    })),
    turn_detection: z.optional(z.object({
        type: z.optional(z.string()),
        threshold: z.optional(z.number()),
        prefix_padding_ms: z.optional(z.int()),
        silence_duration_ms: z.optional(z.int())
    }))
});

/**
 * Returned when a transcription session is updated with a `transcription_session.update` event, unless
 * there is an error.
 *
 */
export const zRealtimeServerEventTranscriptionSessionUpdated = z.object({
    event_id: z.string(),
    type: z.enum(['transcription_session.updated']),
    session: zRealtimeTranscriptionSessionCreateResponse
});

/**
 * **o-series models only**
 *
 * Constrains effort on reasoning for
 * [reasoning models](https://platform.openai.com/docs/guides/reasoning).
 * Currently supported values are `low`, `medium`, and `high`. Reducing
 * reasoning effort can result in faster responses and fewer tokens used
 * on reasoning in a response.
 *
 */
export const zReasoningEffort = z.enum([
    'low',
    'medium',
    'high'
]);

/**
 * EvalResponsesSource
 *
 * A EvalResponsesSource object describing a run data source configuration.
 *
 */
export const zEvalResponsesSource = z.object({
    type: z.enum(['responses']),
    metadata: z.optional(z.union([
        z.record(z.string(), z.unknown()),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    instructions_search: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    created_after: z.optional(z.union([
        z.int().gte(0),
        z.null()
    ])),
    created_before: z.optional(z.union([
        z.int().gte(0),
        z.null()
    ])),
    has_tool_calls: z.optional(z.union([
        z.boolean(),
        z.null()
    ])),
    reasoning_effort: z.optional(zReasoningEffort),
    temperature: z.optional(z.union([
        z.number(),
        z.null()
    ])),
    top_p: z.optional(z.union([
        z.number(),
        z.null()
    ])),
    users: z.optional(z.union([
        z.array(z.string()),
        z.null()
    ])),
    allow_parallel_tool_calls: z.optional(z.union([
        z.boolean(),
        z.null()
    ]))
});

/**
 * Reasoning
 *
 * **o-series models only**
 *
 * Configuration options for
 * [reasoning models](https://platform.openai.com/docs/guides/reasoning).
 *
 */
export const zReasoning = z.object({
    effort: z.optional(zReasoningEffort),
    summary: z.optional(z.enum([
        'auto',
        'concise',
        'detailed'
    ])),
    generate_summary: z.optional(z.enum([
        'auto',
        'concise',
        'detailed'
    ]))
});

/**
 * Reasoning
 *
 * A description of the chain of thought used by a reasoning model while generating
 * a response.
 *
 */
export const zReasoningItem = z.object({
    type: z.enum(['reasoning']),
    id: z.string(),
    summary: z.array(z.object({
        type: z.enum(['summary_text']),
        text: z.string()
    })),
    status: z.optional(z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ]))
});

/**
 * Emitted when there is a partial audio response.
 */
export const zResponseAudioDeltaEvent = z.object({
    type: z.enum(['response.audio.delta']),
    delta: z.string()
});

/**
 * Emitted when the audio response is complete.
 */
export const zResponseAudioDoneEvent = z.object({
    type: z.enum(['response.audio.done'])
});

/**
 * Emitted when there is a partial transcript of audio.
 */
export const zResponseAudioTranscriptDeltaEvent = z.object({
    type: z.enum(['response.audio.transcript.delta']),
    delta: z.string()
});

/**
 * Emitted when the full audio transcript is completed.
 */
export const zResponseAudioTranscriptDoneEvent = z.object({
    type: z.enum(['response.audio.transcript.done'])
});

/**
 * Emitted when a partial code snippet is added by the code interpreter.
 */
export const zResponseCodeInterpreterCallCodeDeltaEvent = z.object({
    type: z.enum(['response.code_interpreter_call.code.delta']),
    output_index: z.int(),
    delta: z.string()
});

/**
 * Emitted when code snippet output is finalized by the code interpreter.
 */
export const zResponseCodeInterpreterCallCodeDoneEvent = z.object({
    type: z.enum(['response.code_interpreter_call.code.done']),
    output_index: z.int(),
    code: z.string()
});

/**
 * Emitted when the code interpreter call is completed.
 */
export const zResponseCodeInterpreterCallCompletedEvent = z.object({
    type: z.enum(['response.code_interpreter_call.completed']),
    output_index: z.int(),
    code_interpreter_call: zCodeInterpreterToolCall
});

/**
 * Emitted when a code interpreter call is in progress.
 */
export const zResponseCodeInterpreterCallInProgressEvent = z.object({
    type: z.enum(['response.code_interpreter_call.in_progress']),
    output_index: z.int(),
    code_interpreter_call: zCodeInterpreterToolCall
});

/**
 * Emitted when the code interpreter is actively interpreting the code snippet.
 */
export const zResponseCodeInterpreterCallInterpretingEvent = z.object({
    type: z.enum(['response.code_interpreter_call.interpreting']),
    output_index: z.int(),
    code_interpreter_call: zCodeInterpreterToolCall
});

/**
 * The error code for the response.
 *
 */
export const zResponseErrorCode = z.enum([
    'server_error',
    'rate_limit_exceeded',
    'invalid_prompt',
    'vector_store_timeout',
    'invalid_image',
    'invalid_image_format',
    'invalid_base64_image',
    'invalid_image_url',
    'image_too_large',
    'image_too_small',
    'image_parse_error',
    'image_content_policy_violation',
    'invalid_image_mode',
    'image_file_too_large',
    'unsupported_image_media_type',
    'empty_image_file',
    'failed_to_download_image',
    'image_file_not_found'
]);

/**
 * An error object returned when the model fails to generate a Response.
 *
 */
export const zResponseError = z.union([
    z.object({
        code: zResponseErrorCode,
        message: z.string()
    }),
    z.null()
]);

/**
 * Emitted when an error occurs.
 */
export const zResponseErrorEvent = z.object({
    type: z.enum(['error']),
    code: z.union([
        z.string(),
        z.null()
    ]),
    message: z.string(),
    param: z.union([
        z.string(),
        z.null()
    ])
});

/**
 * Emitted when a file search call is completed (results found).
 */
export const zResponseFileSearchCallCompletedEvent = z.object({
    type: z.enum(['response.file_search_call.completed']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * Emitted when a file search call is initiated.
 */
export const zResponseFileSearchCallInProgressEvent = z.object({
    type: z.enum(['response.file_search_call.in_progress']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * Emitted when a file search is currently searching.
 */
export const zResponseFileSearchCallSearchingEvent = z.object({
    type: z.enum(['response.file_search_call.searching']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * JSON object
 *
 * JSON object response format. An older method of generating JSON responses.
 * Using `json_schema` is recommended for models that support it. Note that the
 * model will not generate JSON without a system or user message instructing it
 * to do so.
 *
 */
export const zResponseFormatJsonObject = z.object({
    type: z.enum(['json_object'])
});

/**
 * JSON schema
 *
 * The schema for the response format, described as a JSON Schema object.
 * Learn how to build JSON schemas [here](https://json-schema.org/).
 *
 */
export const zResponseFormatJsonSchemaSchema = z.record(z.string(), z.unknown());

/**
 * JSON schema
 *
 * JSON Schema response format. Used to generate structured JSON responses.
 * Learn more about [Structured Outputs](/docs/guides/structured-outputs).
 *
 */
export const zResponseFormatJsonSchema = z.object({
    type: z.enum(['json_schema']),
    json_schema: z.object({
        description: z.optional(z.string()),
        name: z.string(),
        schema: z.optional(zResponseFormatJsonSchemaSchema),
        strict: z.optional(z.union([
            z.boolean().default(false),
            z.null()
        ])).default(false)
    })
});

/**
 * Text
 *
 * Default response format. Used to generate text responses.
 *
 */
export const zResponseFormatText = z.object({
    type: z.enum(['text'])
});

/**
 * Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
 *
 * Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).
 *
 * Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.
 *
 * **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
 *
 */
export const zAssistantsApiResponseFormatOption = z.union([
    z.enum(['auto']),
    zResponseFormatText,
    zResponseFormatJsonObject,
    zResponseFormatJsonSchema
]);

/**
 * Assistant
 *
 * Represents an `assistant` that can call the model and use tools.
 */
export const zAssistantObject = z.object({
    id: z.string(),
    object: z.enum(['assistant']),
    created_at: z.int(),
    name: z.union([
        z.string().max(256),
        z.null()
    ]),
    description: z.union([
        z.string().max(512),
        z.null()
    ]),
    model: z.string(),
    instructions: z.union([
        z.string().max(256000),
        z.null()
    ]),
    tools: z.array(z.union([
        zAssistantToolsCode,
        zAssistantToolsFileSearch,
        zAssistantToolsFunction
    ])).max(128).default([]),
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1))
            }))
        }),
        z.null()
    ])),
    metadata: zMetadata,
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    response_format: z.optional(zAssistantsApiResponseFormatOption)
});

export const zCreateAssistantRequest = z.object({
    model: z.union([
        z.string(),
        zAssistantSupportedModels
    ]),
    name: z.optional(z.union([
        z.string().max(256),
        z.null()
    ])),
    description: z.optional(z.union([
        z.string().max(512),
        z.null()
    ])),
    instructions: z.optional(z.union([
        z.string().max(256000),
        z.null()
    ])),
    reasoning_effort: z.optional(zReasoningEffort),
    tools: z.optional(z.array(z.union([
        zAssistantToolsCode,
        zAssistantToolsFileSearch,
        zAssistantToolsFunction
    ])).max(128)).default([]),
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.intersection(z.unknown(), z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1)),
                vector_stores: z.optional(z.array(z.object({
                    file_ids: z.optional(z.array(z.string()).max(10000)),
                    chunking_strategy: z.optional(z.union([
                        z.object({
                            type: z.enum(['auto'])
                        }),
                        z.object({
                            type: z.enum(['static']),
                            static: z.object({
                                max_chunk_size_tokens: z.int().gte(100).lte(4096),
                                chunk_overlap_tokens: z.int()
                            })
                        })
                    ])),
                    metadata: z.optional(zMetadata)
                })).max(1))
            })))
        }),
        z.null()
    ])),
    metadata: z.optional(zMetadata),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    response_format: z.optional(zAssistantsApiResponseFormatOption)
});

export const zListAssistantsResponse = z.object({
    object: z.string(),
    data: z.array(zAssistantObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zModifyAssistantRequest = z.object({
    model: z.optional(z.union([
        z.string(),
        zAssistantSupportedModels
    ])),
    reasoning_effort: z.optional(zReasoningEffort),
    name: z.optional(z.union([
        z.string().max(256),
        z.null()
    ])),
    description: z.optional(z.union([
        z.string().max(512),
        z.null()
    ])),
    instructions: z.optional(z.union([
        z.string().max(256000),
        z.null()
    ])),
    tools: z.optional(z.array(z.union([
        zAssistantToolsCode,
        zAssistantToolsFileSearch,
        zAssistantToolsFunction
    ])).max(128)).default([]),
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1))
            }))
        }),
        z.null()
    ])),
    metadata: z.optional(zMetadata),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    response_format: z.optional(zAssistantsApiResponseFormatOption)
});

/**
 * Emitted when there is a partial function-call arguments delta.
 */
export const zResponseFunctionCallArgumentsDeltaEvent = z.object({
    type: z.enum(['response.function_call_arguments.delta']),
    item_id: z.string(),
    output_index: z.int(),
    delta: z.string()
});

/**
 * Emitted when function-call arguments are finalized.
 */
export const zResponseFunctionCallArgumentsDoneEvent = z.object({
    type: z.enum(['response.function_call_arguments.done']),
    item_id: z.string(),
    output_index: z.int(),
    arguments: z.string()
});

/**
 * Output types that you would like the model to generate.
 * Most models are capable of generating text, which is the default:
 *
 * `["text"]`
 *
 * The `gpt-4o-audio-preview` model can also be used to
 * [generate audio](/docs/guides/audio). To request that this model generate
 * both text and audio responses, you can use:
 *
 * `["text", "audio"]`
 *
 */
export const zResponseModalities = z.union([
    z.array(z.enum(['text', 'audio'])),
    z.null()
]);

/**
 * Emitted when a new reasoning summary part is added.
 */
export const zResponseReasoningSummaryPartAddedEvent = z.object({
    type: z.enum(['response.reasoning_summary_part.added']),
    item_id: z.string(),
    output_index: z.int(),
    summary_index: z.int(),
    part: z.object({
        type: z.enum(['summary_text']),
        text: z.string()
    })
});

/**
 * Emitted when a reasoning summary part is completed.
 */
export const zResponseReasoningSummaryPartDoneEvent = z.object({
    type: z.enum(['response.reasoning_summary_part.done']),
    item_id: z.string(),
    output_index: z.int(),
    summary_index: z.int(),
    part: z.object({
        type: z.enum(['summary_text']),
        text: z.string()
    })
});

/**
 * Emitted when a delta is added to a reasoning summary text.
 */
export const zResponseReasoningSummaryTextDeltaEvent = z.object({
    type: z.enum(['response.reasoning_summary_text.delta']),
    item_id: z.string(),
    output_index: z.int(),
    summary_index: z.int(),
    delta: z.string()
});

/**
 * Emitted when a reasoning summary text is completed.
 */
export const zResponseReasoningSummaryTextDoneEvent = z.object({
    type: z.enum(['response.reasoning_summary_text.done']),
    item_id: z.string(),
    output_index: z.int(),
    summary_index: z.int(),
    text: z.string()
});

/**
 * Emitted when there is a partial refusal text.
 */
export const zResponseRefusalDeltaEvent = z.object({
    type: z.enum(['response.refusal.delta']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    delta: z.string()
});

/**
 * Emitted when refusal text is finalized.
 */
export const zResponseRefusalDoneEvent = z.object({
    type: z.enum(['response.refusal.done']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    refusal: z.string()
});

/**
 * Emitted when there is an additional text delta.
 */
export const zResponseTextDeltaEvent = z.object({
    type: z.enum(['response.output_text.delta']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    delta: z.string()
});

/**
 * Emitted when text content is finalized.
 */
export const zResponseTextDoneEvent = z.object({
    type: z.enum(['response.output_text.done']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    text: z.string()
});

/**
 * Represents token usage details including input tokens, output tokens,
 * a breakdown of output tokens, and the total tokens used.
 *
 */
export const zResponseUsage = z.object({
    input_tokens: z.int(),
    input_tokens_details: z.object({
        cached_tokens: z.int()
    }),
    output_tokens: z.int(),
    output_tokens_details: z.object({
        reasoning_tokens: z.int()
    }),
    total_tokens: z.int()
});

/**
 * Emitted when a web search call is completed.
 */
export const zResponseWebSearchCallCompletedEvent = z.object({
    type: z.enum(['response.web_search_call.completed']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * Emitted when a web search call is initiated.
 */
export const zResponseWebSearchCallInProgressEvent = z.object({
    type: z.enum(['response.web_search_call.in_progress']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * Emitted when a web search call is executing.
 */
export const zResponseWebSearchCallSearchingEvent = z.object({
    type: z.enum(['response.web_search_call.searching']),
    output_index: z.int(),
    item_id: z.string()
});

/**
 * Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).
 */
export const zRunCompletionUsage = z.union([
    z.object({
        completion_tokens: z.int(),
        prompt_tokens: z.int(),
        total_tokens: z.int()
    }),
    z.null()
]);

/**
 * Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.
 */
export const zRunStepCompletionUsage = z.union([
    z.object({
        completion_tokens: z.int(),
        prompt_tokens: z.int(),
        total_tokens: z.int()
    }),
    z.null()
]);

/**
 * Message creation
 *
 * Details of the message creation by the run step.
 */
export const zRunStepDeltaStepDetailsMessageCreationObject = z.object({
    type: z.enum(['message_creation']),
    message_creation: z.optional(z.object({
        message_id: z.optional(z.string())
    }))
});

/**
 * Code interpreter image output
 */
export const zRunStepDeltaStepDetailsToolCallsCodeOutputImageObject = z.object({
    index: z.int(),
    type: z.enum(['image']),
    image: z.optional(z.object({
        file_id: z.optional(z.string())
    }))
});

/**
 * Code interpreter log output
 *
 * Text output from the Code Interpreter tool call as part of a run step.
 */
export const zRunStepDeltaStepDetailsToolCallsCodeOutputLogsObject = z.object({
    index: z.int(),
    type: z.enum(['logs']),
    logs: z.optional(z.string())
});

/**
 * Code interpreter tool call
 *
 * Details of the Code Interpreter tool call the run step was involved in.
 */
export const zRunStepDeltaStepDetailsToolCallsCodeObject = z.object({
    index: z.int(),
    id: z.optional(z.string()),
    type: z.enum(['code_interpreter']),
    code_interpreter: z.optional(z.object({
        input: z.optional(z.string()),
        outputs: z.optional(z.array(z.union([zRunStepDeltaStepDetailsToolCallsCodeOutputLogsObject, zRunStepDeltaStepDetailsToolCallsCodeOutputImageObject])))
    }))
});

/**
 * File search tool call
 */
export const zRunStepDeltaStepDetailsToolCallsFileSearchObject = z.object({
    index: z.int(),
    id: z.optional(z.string()),
    type: z.enum(['file_search']),
    file_search: z.record(z.string(), z.unknown())
});

/**
 * Function tool call
 */
export const zRunStepDeltaStepDetailsToolCallsFunctionObject = z.object({
    index: z.int(),
    id: z.optional(z.string()),
    type: z.enum(['function']),
    function: z.optional(z.object({
        name: z.optional(z.string()),
        arguments: z.optional(z.string()),
        output: z.optional(z.union([
            z.string(),
            z.null()
        ]))
    }))
});

/**
 * Tool calls
 *
 * Details of the tool call.
 */
export const zRunStepDeltaStepDetailsToolCallsObject = z.object({
    type: z.enum(['tool_calls']),
    tool_calls: z.optional(z.array(z.union([
        zRunStepDeltaStepDetailsToolCallsCodeObject,
        zRunStepDeltaStepDetailsToolCallsFileSearchObject,
        zRunStepDeltaStepDetailsToolCallsFunctionObject
    ])))
});

/**
 * Run step delta object
 *
 * Represents a run step delta i.e. any changed fields on a run step during streaming.
 *
 */
export const zRunStepDeltaObject = z.object({
    id: z.string(),
    object: z.enum(['thread.run.step.delta']),
    delta: z.object({
        step_details: z.optional(z.union([
            zRunStepDeltaStepDetailsMessageCreationObject,
            zRunStepDeltaStepDetailsToolCallsObject
        ]))
    })
});

/**
 * Message creation
 *
 * Details of the message creation by the run step.
 */
export const zRunStepDetailsMessageCreationObject = z.object({
    type: z.enum(['message_creation']),
    message_creation: z.object({
        message_id: z.string()
    })
});

/**
 * Code Interpreter image output
 */
export const zRunStepDetailsToolCallsCodeOutputImageObject = z.object({
    type: z.enum(['image']),
    image: z.object({
        file_id: z.string()
    })
});

/**
 * Code Interpreter log output
 *
 * Text output from the Code Interpreter tool call as part of a run step.
 */
export const zRunStepDetailsToolCallsCodeOutputLogsObject = z.object({
    type: z.enum(['logs']),
    logs: z.string()
});

/**
 * Code Interpreter tool call
 *
 * Details of the Code Interpreter tool call the run step was involved in.
 */
export const zRunStepDetailsToolCallsCodeObject = z.object({
    id: z.string(),
    type: z.enum(['code_interpreter']),
    code_interpreter: z.object({
        input: z.string(),
        outputs: z.array(z.union([zRunStepDetailsToolCallsCodeOutputLogsObject, zRunStepDetailsToolCallsCodeOutputImageObject]))
    })
});

/**
 * File search tool call ranking options
 *
 * The ranking options for the file search.
 */
export const zRunStepDetailsToolCallsFileSearchRankingOptionsObject = z.object({
    ranker: zFileSearchRanker,
    score_threshold: z.number().gte(0).lte(1)
});

/**
 * File search tool call result
 *
 * A result instance of the file search.
 */
export const zRunStepDetailsToolCallsFileSearchResultObject = z.object({
    file_id: z.string(),
    file_name: z.string(),
    score: z.number().gte(0).lte(1),
    content: z.optional(z.array(z.object({
        type: z.optional(z.enum(['text'])),
        text: z.optional(z.string())
    })))
});

/**
 * File search tool call
 */
export const zRunStepDetailsToolCallsFileSearchObject = z.object({
    id: z.string(),
    type: z.enum(['file_search']),
    file_search: z.object({
        ranking_options: z.optional(zRunStepDetailsToolCallsFileSearchRankingOptionsObject),
        results: z.optional(z.array(zRunStepDetailsToolCallsFileSearchResultObject))
    })
});

/**
 * Function tool call
 */
export const zRunStepDetailsToolCallsFunctionObject = z.object({
    id: z.string(),
    type: z.enum(['function']),
    function: z.object({
        name: z.string(),
        arguments: z.string(),
        output: z.union([
            z.string(),
            z.null()
        ])
    })
});

/**
 * Tool calls
 *
 * Details of the tool call.
 */
export const zRunStepDetailsToolCallsObject = z.object({
    type: z.enum(['tool_calls']),
    tool_calls: z.array(z.union([
        zRunStepDetailsToolCallsCodeObject,
        zRunStepDetailsToolCallsFileSearchObject,
        zRunStepDetailsToolCallsFunctionObject
    ]))
});

/**
 * Run steps
 *
 * Represents a step in execution of a run.
 *
 */
export const zRunStepObject = z.object({
    id: z.string(),
    object: z.enum(['thread.run.step']),
    created_at: z.int(),
    assistant_id: z.string(),
    thread_id: z.string(),
    run_id: z.string(),
    type: z.enum(['message_creation', 'tool_calls']),
    status: z.enum([
        'in_progress',
        'cancelled',
        'failed',
        'completed',
        'expired'
    ]),
    step_details: z.union([
        zRunStepDetailsMessageCreationObject,
        zRunStepDetailsToolCallsObject
    ]),
    last_error: z.union([
        z.object({
            code: z.enum(['server_error', 'rate_limit_exceeded']),
            message: z.string()
        }),
        z.null()
    ]),
    expired_at: z.union([
        z.int(),
        z.null()
    ]),
    cancelled_at: z.union([
        z.int(),
        z.null()
    ]),
    failed_at: z.union([
        z.int(),
        z.null()
    ]),
    completed_at: z.union([
        z.int(),
        z.null()
    ]),
    metadata: zMetadata,
    usage: zRunStepCompletionUsage
});

export const zListRunStepsResponse = z.object({
    object: z.string(),
    data: z.array(zRunStepObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zRunStepStreamEvent = z.union([
    z.object({
        event: z.enum(['thread.run.step.created']),
        data: zRunStepObject
    }),
    z.object({
        event: z.enum(['thread.run.step.in_progress']),
        data: zRunStepObject
    }),
    z.object({
        event: z.enum(['thread.run.step.delta']),
        data: zRunStepDeltaObject
    }),
    z.object({
        event: z.enum(['thread.run.step.completed']),
        data: zRunStepObject
    }),
    z.object({
        event: z.enum(['thread.run.step.failed']),
        data: zRunStepObject
    }),
    z.object({
        event: z.enum(['thread.run.step.cancelled']),
        data: zRunStepObject
    }),
    z.object({
        event: z.enum(['thread.run.step.expired']),
        data: zRunStepObject
    })
]);

/**
 * Tool call objects
 */
export const zRunToolCallObject = z.object({
    id: z.string(),
    type: z.enum(['function']),
    function: z.object({
        name: z.string(),
        arguments: z.string()
    })
});

/**
 * Screenshot
 *
 * A screenshot action.
 *
 */
export const zScreenshot = z.object({
    type: z.enum(['screenshot'])
});

/**
 * Scroll
 *
 * A scroll action.
 *
 */
export const zScroll = z.object({
    type: z.enum(['scroll']),
    x: z.int(),
    y: z.int(),
    scroll_x: z.int(),
    scroll_y: z.int()
});

/**
 * Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:
 * - If set to 'auto', and the Project is Scale tier enabled, the system
 * will utilize scale tier credits until they are exhausted.
 * - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
 * - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
 * - If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
 * - When not set, the default behavior is 'auto'.
 *
 * When this parameter is set, the response body will include the `service_tier` utilized.
 *
 */
export const zServiceTier = z.enum([
    'auto',
    'default',
    'flex'
]);

/**
 * Represents a chat completion response returned by model, based on the provided input.
 */
export const zCreateChatCompletionResponse = z.object({
    id: z.string(),
    choices: z.array(z.object({
        finish_reason: z.enum([
            'stop',
            'length',
            'tool_calls',
            'content_filter',
            'function_call'
        ]),
        index: z.int(),
        message: zChatCompletionResponseMessage,
        logprobs: z.union([
            z.object({
                content: z.union([
                    z.array(zChatCompletionTokenLogprob),
                    z.null()
                ]),
                refusal: z.union([
                    z.array(zChatCompletionTokenLogprob),
                    z.null()
                ])
            }),
            z.null()
        ])
    })),
    created: z.int(),
    model: z.string(),
    service_tier: z.optional(zServiceTier),
    system_fingerprint: z.optional(z.string()),
    object: z.enum(['chat.completion']),
    usage: z.optional(zCompletionUsage)
});

/**
 * ChatCompletionList
 *
 * An object representing a list of Chat Completions.
 *
 */
export const zChatCompletionList = z.object({
    object: z.enum(['list']),
    data: z.array(zCreateChatCompletionResponse),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Represents a streamed chunk of a chat completion response returned
 * by the model, based on the provided input.
 * [Learn more](/docs/guides/streaming-responses).
 *
 */
export const zCreateChatCompletionStreamResponse = z.object({
    id: z.string(),
    choices: z.array(z.object({
        delta: zChatCompletionStreamResponseDelta,
        logprobs: z.optional(z.union([
            z.object({
                content: z.union([
                    z.array(zChatCompletionTokenLogprob),
                    z.null()
                ]),
                refusal: z.union([
                    z.array(zChatCompletionTokenLogprob),
                    z.null()
                ])
            }),
            z.null()
        ])),
        finish_reason: z.enum([
            'stop',
            'length',
            'tool_calls',
            'content_filter',
            'function_call'
        ]),
        index: z.int()
    })),
    created: z.int(),
    model: z.string(),
    service_tier: z.optional(zServiceTier),
    system_fingerprint: z.optional(z.string()),
    object: z.enum(['chat.completion.chunk']),
    usage: z.optional(zCompletionUsage)
});

export const zModelResponseProperties = z.object({
    metadata: z.optional(zMetadata),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    user: z.optional(z.string()),
    service_tier: z.optional(zServiceTier)
});

export const zCreateModelResponseProperties = zModelResponseProperties;

export const zStaticChunkingStrategy = z.object({
    max_chunk_size_tokens: z.int().gte(100).lte(4096),
    chunk_overlap_tokens: z.int()
});

/**
 * Static Chunking Strategy
 *
 * Customize your own chunking strategy by setting chunk size and chunk overlap.
 */
export const zStaticChunkingStrategyRequestParam = z.object({
    type: z.enum(['static']),
    static: zStaticChunkingStrategy
});

/**
 * The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.
 */
export const zChunkingStrategyRequestParam = z.union([
    zAutoChunkingStrategyRequestParam,
    zStaticChunkingStrategyRequestParam
]);

/**
 * Static Chunking Strategy
 */
export const zStaticChunkingStrategyResponseParam = z.object({
    type: z.enum(['static']),
    static: zStaticChunkingStrategy
});

/**
 * Not supported with latest reasoning models `o3` and `o4-mini`.
 *
 * Up to 4 sequences where the API will stop generating further tokens. The
 * returned text will not contain the stop sequence.
 *
 */
export const zStopConfiguration = z.union([
    z.string().default('<|endoftext|>'),
    z.null(),
    z.array(z.string()).min(1).max(4)
]);

export const zCreateCompletionRequest = z.object({
    model: z.union([
        z.string(),
        z.enum([
            'gpt-3.5-turbo-instruct',
            'davinci-002',
            'babbage-002'
        ])
    ]),
    prompt: z.union([
        z.string().default(''),
        z.array(z.string().default('')),
        z.array(z.int()).min(1),
        z.array(z.array(z.int()).min(1)).min(1),
        z.null()
    ]),
    best_of: z.optional(z.union([
        z.int().gte(0).lte(20).default(1),
        z.null()
    ])).default(1),
    echo: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false),
    frequency_penalty: z.optional(z.union([
        z.number().gte(-2).lte(2).default(0),
        z.null()
    ])).default(0),
    logit_bias: z.optional(z.union([
        z.record(z.string(), z.int()),
        z.null()
    ])).default(null),
    logprobs: z.optional(z.union([
        z.int().gte(0).lte(5),
        z.null()
    ])).default(null),
    max_tokens: z.optional(z.union([
        z.int().gte(0).default(16),
        z.null()
    ])).default(16),
    n: z.optional(z.union([
        z.int().gte(1).lte(128).default(1),
        z.null()
    ])).default(1),
    presence_penalty: z.optional(z.union([
        z.number().gte(-2).lte(2).default(0),
        z.null()
    ])).default(0),
    seed: z.optional(z.union([
        z.coerce.bigint().min(BigInt('-9223372036854775808'), { error: 'Invalid value: Expected int64 to be >= -9223372036854775808' }).max(BigInt('9223372036854775807'), { error: 'Invalid value: Expected int64 to be <= 9223372036854775807' }),
        z.null()
    ])),
    stop: z.optional(zStopConfiguration),
    stream: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false),
    stream_options: z.optional(zChatCompletionStreamOptions),
    suffix: z.optional(z.union([
        z.string(),
        z.null()
    ])).default(null),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    user: z.optional(z.string())
});

export const zSubmitToolOutputsRunRequest = z.object({
    tool_outputs: z.array(z.object({
        tool_call_id: z.optional(z.string()),
        output: z.optional(z.string())
    })),
    stream: z.optional(z.union([
        z.boolean(),
        z.null()
    ]))
});

/**
 * JSON schema
 *
 * JSON Schema response format. Used to generate structured JSON responses.
 * Learn more about [Structured Outputs](/docs/guides/structured-outputs).
 *
 */
export const zTextResponseFormatJsonSchema = z.object({
    type: z.enum(['json_schema']),
    description: z.optional(z.string()),
    name: z.string(),
    schema: zResponseFormatJsonSchemaSchema,
    strict: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false)
});

/**
 * An object specifying the format that the model must output.
 *
 * Configuring `{ "type": "json_schema" }` enables Structured Outputs,
 * which ensures the model will match your supplied JSON schema. Learn more in the
 * [Structured Outputs guide](/docs/guides/structured-outputs).
 *
 * The default format is `{ "type": "text" }` with no additional options.
 *
 * **Not recommended for gpt-4o and newer models:**
 *
 * Setting to `{ "type": "json_object" }` enables the older JSON mode, which
 * ensures the message the model generates is valid JSON. Using `json_schema`
 * is preferred for models that support it.
 *
 */
export const zTextResponseFormatConfiguration = z.union([
    zResponseFormatText,
    zTextResponseFormatJsonSchema,
    zResponseFormatJsonObject
]);

/**
 * Thread
 *
 * Represents a thread that contains [messages](/docs/api-reference/messages).
 */
export const zThreadObject = z.object({
    id: z.string(),
    object: z.enum(['thread']),
    created_at: z.int(),
    tool_resources: z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1))
            }))
        }),
        z.null()
    ]),
    metadata: zMetadata
});

/**
 * Occurs when a new [thread](/docs/api-reference/threads/object) is created.
 */
export const zThreadStreamEvent = z.object({
    enabled: z.optional(z.boolean()),
    event: z.enum(['thread.created']),
    data: zThreadObject
});

export const zToggleCertificatesRequest = z.object({
    certificate_ids: z.array(z.string()).min(1).max(10)
});

/**
 * Function tool
 *
 * Use this option to force the model to call a specific function.
 *
 */
export const zToolChoiceFunction = z.object({
    type: z.enum(['function']),
    name: z.string()
});

/**
 * Tool choice mode
 *
 * Controls which (if any) tool is called by the model.
 *
 * `none` means the model will not call any tool and instead generates a message.
 *
 * `auto` means the model can pick between generating a message or calling one or
 * more tools.
 *
 * `required` means the model must call one or more tools.
 *
 */
export const zToolChoiceOptions = z.enum([
    'none',
    'auto',
    'required'
]);

/**
 * Hosted tool
 *
 * Indicates that the model should use a built-in tool to generate a response.
 * [Learn more about built-in tools](/docs/guides/tools).
 *
 */
export const zToolChoiceTypes = z.object({
    type: z.enum([
        'file_search',
        'web_search_preview',
        'computer_use_preview',
        'web_search_preview_2025_03_11'
    ])
});

/**
 * Emitted when there is an additional text delta. This is also the first event emitted when the transcription starts. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.
 */
export const zTranscriptTextDeltaEvent = z.object({
    type: z.enum(['transcript.text.delta']),
    delta: z.string(),
    logprobs: z.optional(z.array(z.object({
        token: z.optional(z.string()),
        logprob: z.optional(z.number()),
        bytes: z.optional(z.array(z.unknown()))
    })))
});

/**
 * Emitted when the transcription is complete. Contains the complete transcription text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.
 */
export const zTranscriptTextDoneEvent = z.object({
    type: z.enum(['transcript.text.done']),
    text: z.string(),
    logprobs: z.optional(z.array(z.object({
        token: z.optional(z.string()),
        logprob: z.optional(z.number()),
        bytes: z.optional(z.array(z.unknown()))
    })))
});

export const zCreateTranscriptionResponseStreamEvent = z.union([
    z.object({
        type: z.optional(z.literal('TranscriptTextDeltaEvent'))
    }).and(zTranscriptTextDeltaEvent),
    z.object({
        type: z.optional(z.literal('TranscriptTextDoneEvent'))
    }).and(zTranscriptTextDoneEvent)
]);

export const zTranscriptionInclude = z.enum(['logprobs']);

export const zCreateTranscriptionRequest = z.object({
    file: z.string(),
    model: z.union([
        z.string(),
        z.enum([
            'whisper-1',
            'gpt-4o-transcribe',
            'gpt-4o-mini-transcribe'
        ])
    ]),
    language: z.optional(z.string()),
    prompt: z.optional(z.string()),
    response_format: z.optional(zAudioResponseFormat),
    temperature: z.optional(z.number()).default(0),
    'include[]': z.optional(z.array(zTranscriptionInclude)),
    'timestamp_granularities[]': z.optional(z.array(z.enum(['word', 'segment']))).default(['segment']),
    stream: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false)
});

export const zTranscriptionSegment = z.object({
    id: z.int(),
    seek: z.int(),
    start: z.number(),
    end: z.number(),
    text: z.string(),
    tokens: z.array(z.int()),
    temperature: z.number(),
    avg_logprob: z.number(),
    compression_ratio: z.number(),
    no_speech_prob: z.number()
});

export const zCreateTranslationResponseVerboseJson = z.object({
    language: z.string(),
    duration: z.number(),
    text: z.string(),
    segments: z.optional(z.array(zTranscriptionSegment))
});

export const zTranscriptionWord = z.object({
    word: z.string(),
    start: z.number(),
    end: z.number()
});

/**
 * Represents a verbose json transcription response returned by model, based on the provided input.
 */
export const zCreateTranscriptionResponseVerboseJson = z.object({
    language: z.string(),
    duration: z.number(),
    text: z.string(),
    words: z.optional(z.array(zTranscriptionWord)),
    segments: z.optional(z.array(zTranscriptionSegment))
});

/**
 * Thread Truncation Controls
 *
 * Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.
 */
export const zTruncationObject = z.object({
    type: z.enum(['auto', 'last_messages']),
    last_messages: z.optional(z.union([
        z.int().gte(1),
        z.null()
    ]))
});

export const zCreateRunRequest = z.object({
    assistant_id: z.string(),
    model: z.optional(z.union([
        z.string(),
        zAssistantSupportedModels,
        z.null()
    ])),
    reasoning_effort: z.optional(zReasoningEffort),
    instructions: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    additional_instructions: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    additional_messages: z.optional(z.union([
        z.array(zCreateMessageRequest),
        z.null()
    ])),
    tools: z.optional(z.union([
        z.array(z.union([
            zAssistantToolsCode,
            zAssistantToolsFileSearch,
            zAssistantToolsFunction
        ])).max(20),
        z.null()
    ])),
    metadata: z.optional(zMetadata),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    stream: z.optional(z.union([
        z.boolean(),
        z.null()
    ])),
    max_prompt_tokens: z.optional(z.union([
        z.int().gte(256),
        z.null()
    ])),
    max_completion_tokens: z.optional(z.union([
        z.int().gte(256),
        z.null()
    ])),
    truncation_strategy: z.optional(zTruncationObject.and(z.unknown())),
    tool_choice: z.optional(zAssistantsApiToolChoiceOption.and(z.unknown())),
    parallel_tool_calls: z.optional(zParallelToolCalls),
    response_format: z.optional(zAssistantsApiResponseFormatOption)
});

export const zCreateThreadAndRunRequest = z.object({
    assistant_id: z.string(),
    thread: z.optional(zCreateThreadRequest),
    model: z.optional(z.union([
        z.string(),
        z.enum([
            'gpt-4.1',
            'gpt-4.1-mini',
            'gpt-4.1-nano',
            'gpt-4.1-2025-04-14',
            'gpt-4.1-mini-2025-04-14',
            'gpt-4.1-nano-2025-04-14',
            'gpt-4o',
            'gpt-4o-2024-11-20',
            'gpt-4o-2024-08-06',
            'gpt-4o-2024-05-13',
            'gpt-4o-mini',
            'gpt-4o-mini-2024-07-18',
            'gpt-4.5-preview',
            'gpt-4.5-preview-2025-02-27',
            'gpt-4-turbo',
            'gpt-4-turbo-2024-04-09',
            'gpt-4-0125-preview',
            'gpt-4-turbo-preview',
            'gpt-4-1106-preview',
            'gpt-4-vision-preview',
            'gpt-4',
            'gpt-4-0314',
            'gpt-4-0613',
            'gpt-4-32k',
            'gpt-4-32k-0314',
            'gpt-4-32k-0613',
            'gpt-3.5-turbo',
            'gpt-3.5-turbo-16k',
            'gpt-3.5-turbo-0613',
            'gpt-3.5-turbo-1106',
            'gpt-3.5-turbo-0125',
            'gpt-3.5-turbo-16k-0613'
        ]),
        z.null()
    ])),
    instructions: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    tools: z.optional(z.union([
        z.array(z.union([
            zAssistantToolsCode,
            zAssistantToolsFileSearch,
            zAssistantToolsFunction
        ])).max(20),
        z.null()
    ])),
    tool_resources: z.optional(z.union([
        z.object({
            code_interpreter: z.optional(z.object({
                file_ids: z.optional(z.array(z.string()).max(20)).default([])
            })),
            file_search: z.optional(z.object({
                vector_store_ids: z.optional(z.array(z.string()).max(1))
            }))
        }),
        z.null()
    ])),
    metadata: z.optional(zMetadata),
    temperature: z.optional(z.union([
        z.number().gte(0).lte(2).default(1),
        z.null()
    ])).default(1),
    top_p: z.optional(z.union([
        z.number().gte(0).lte(1).default(1),
        z.null()
    ])).default(1),
    stream: z.optional(z.union([
        z.boolean(),
        z.null()
    ])),
    max_prompt_tokens: z.optional(z.union([
        z.int().gte(256),
        z.null()
    ])),
    max_completion_tokens: z.optional(z.union([
        z.int().gte(256),
        z.null()
    ])),
    truncation_strategy: z.optional(zTruncationObject.and(z.unknown())),
    tool_choice: z.optional(zAssistantsApiToolChoiceOption.and(z.unknown())),
    parallel_tool_calls: z.optional(zParallelToolCalls),
    response_format: z.optional(zAssistantsApiResponseFormatOption)
});

/**
 * A run on a thread
 *
 * Represents an execution run on a [thread](/docs/api-reference/threads).
 */
export const zRunObject = z.object({
    id: z.string(),
    object: z.enum(['thread.run']),
    created_at: z.int(),
    thread_id: z.string(),
    assistant_id: z.string(),
    status: z.enum([
        'queued',
        'in_progress',
        'requires_action',
        'cancelling',
        'cancelled',
        'failed',
        'completed',
        'incomplete',
        'expired'
    ]),
    required_action: z.union([
        z.object({
            type: z.enum(['submit_tool_outputs']),
            submit_tool_outputs: z.object({
                tool_calls: z.array(zRunToolCallObject)
            })
        }),
        z.null()
    ]),
    last_error: z.union([
        z.object({
            code: z.enum([
                'server_error',
                'rate_limit_exceeded',
                'invalid_prompt'
            ]),
            message: z.string()
        }),
        z.null()
    ]),
    expires_at: z.union([
        z.int(),
        z.null()
    ]),
    started_at: z.union([
        z.int(),
        z.null()
    ]),
    cancelled_at: z.union([
        z.int(),
        z.null()
    ]),
    failed_at: z.union([
        z.int(),
        z.null()
    ]),
    completed_at: z.union([
        z.int(),
        z.null()
    ]),
    incomplete_details: z.union([
        z.object({
            reason: z.optional(z.enum(['max_completion_tokens', 'max_prompt_tokens']))
        }),
        z.null()
    ]),
    model: z.string(),
    instructions: z.string(),
    tools: z.array(z.union([
        zAssistantToolsCode,
        zAssistantToolsFileSearch,
        zAssistantToolsFunction
    ])).max(20).default([]),
    metadata: zMetadata,
    usage: zRunCompletionUsage,
    temperature: z.optional(z.union([
        z.number(),
        z.null()
    ])),
    top_p: z.optional(z.union([
        z.number(),
        z.null()
    ])),
    max_prompt_tokens: z.union([
        z.int().gte(256),
        z.null()
    ]),
    max_completion_tokens: z.union([
        z.int().gte(256),
        z.null()
    ]),
    truncation_strategy: zTruncationObject.and(z.unknown()),
    tool_choice: zAssistantsApiToolChoiceOption.and(z.unknown()),
    parallel_tool_calls: zParallelToolCalls,
    response_format: zAssistantsApiResponseFormatOption
});

export const zListRunsResponse = z.object({
    object: z.string(),
    data: z.array(zRunObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zRunStreamEvent = z.union([
    z.object({
        event: z.enum(['thread.run.created']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.queued']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.in_progress']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.requires_action']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.completed']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.incomplete']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.failed']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.cancelling']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.cancelled']),
        data: zRunObject
    }),
    z.object({
        event: z.enum(['thread.run.expired']),
        data: zRunObject
    })
]);

/**
 * Represents an event emitted when streaming a Run.
 *
 * Each event in a server-sent events stream has an `event` and `data` property:
 *
 * ```
 * event: thread.created
 * data: {"id": "thread_123", "object": "thread", ...}
 * ```
 *
 * We emit events whenever a new object is created, transitions to a new state, or is being
 * streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
 * is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
 * to create a message during a run, we emit a `thread.message.created event`, a
 * `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
 * `thread.message.completed` event.
 *
 * We may add additional events over time, so we recommend handling unknown events gracefully
 * in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
 * integrate the Assistants API with streaming.
 *
 */
export const zAssistantStreamEvent = z.union([
    zThreadStreamEvent,
    zRunStreamEvent,
    zRunStepStreamEvent,
    zMessageStreamEvent,
    zErrorEvent,
    zDoneEvent
]);

/**
 * Type
 *
 * An action to type in text.
 *
 */
export const zType = z.object({
    type: z.enum(['type']),
    text: z.string()
});

/**
 * Upload
 *
 * The Upload object can accept byte chunks in the form of Parts.
 *
 */
export const zUpload = z.object({
    id: z.string(),
    created_at: z.int(),
    filename: z.string(),
    bytes: z.int(),
    purpose: z.string(),
    status: z.enum([
        'pending',
        'completed',
        'cancelled',
        'expired'
    ]),
    expires_at: z.int(),
    object: z.optional(z.enum(['upload'])),
    file: z.optional(zOpenAiFile.and(z.unknown()))
});

export const zUploadCertificateRequest = z.object({
    name: z.optional(z.string()),
    content: z.string()
});

/**
 * UploadPart
 *
 * The upload Part represents a chunk of bytes we can add to an Upload object.
 *
 */
export const zUploadPart = z.object({
    id: z.string(),
    created_at: z.int(),
    upload_id: z.string(),
    object: z.enum(['upload.part'])
});

/**
 * The aggregated audio speeches usage details of the specific time bucket.
 */
export const zUsageAudioSpeechesResult = z.object({
    object: z.enum(['organization.usage.audio_speeches.result']),
    characters: z.int(),
    num_model_requests: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated audio transcriptions usage details of the specific time bucket.
 */
export const zUsageAudioTranscriptionsResult = z.object({
    object: z.enum(['organization.usage.audio_transcriptions.result']),
    seconds: z.int(),
    num_model_requests: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated code interpreter sessions usage details of the specific time bucket.
 */
export const zUsageCodeInterpreterSessionsResult = z.object({
    object: z.enum(['organization.usage.code_interpreter_sessions.result']),
    num_sessions: z.optional(z.int()),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated completions usage details of the specific time bucket.
 */
export const zUsageCompletionsResult = z.object({
    object: z.enum(['organization.usage.completions.result']),
    input_tokens: z.int(),
    input_cached_tokens: z.optional(z.int()),
    output_tokens: z.int(),
    input_audio_tokens: z.optional(z.int()),
    output_audio_tokens: z.optional(z.int()),
    num_model_requests: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    batch: z.optional(z.union([
        z.boolean(),
        z.null()
    ]))
});

/**
 * The aggregated embeddings usage details of the specific time bucket.
 */
export const zUsageEmbeddingsResult = z.object({
    object: z.enum(['organization.usage.embeddings.result']),
    input_tokens: z.int(),
    num_model_requests: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated images usage details of the specific time bucket.
 */
export const zUsageImagesResult = z.object({
    object: z.enum(['organization.usage.images.result']),
    images: z.int(),
    num_model_requests: z.int(),
    source: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    size: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated moderations usage details of the specific time bucket.
 */
export const zUsageModerationsResult = z.object({
    object: z.enum(['organization.usage.moderations.result']),
    input_tokens: z.int(),
    num_model_requests: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    user_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    api_key_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

/**
 * The aggregated vector stores usage details of the specific time bucket.
 */
export const zUsageVectorStoresResult = z.object({
    object: z.enum(['organization.usage.vector_stores.result']),
    usage_bytes: z.int(),
    project_id: z.optional(z.union([
        z.string(),
        z.null()
    ]))
});

export const zUsageTimeBucket = z.object({
    object: z.enum(['bucket']),
    start_time: z.int(),
    end_time: z.int(),
    result: z.array(z.union([
        zUsageCompletionsResult,
        zUsageEmbeddingsResult,
        zUsageModerationsResult,
        zUsageImagesResult,
        zUsageAudioSpeechesResult,
        zUsageAudioTranscriptionsResult,
        zUsageVectorStoresResult,
        zUsageCodeInterpreterSessionsResult,
        zCostsResult
    ]))
});

export const zUsageResponse = z.object({
    object: z.enum(['page']),
    data: z.array(zUsageTimeBucket),
    has_more: z.boolean(),
    next_page: z.string()
});

/**
 * Represents an individual `user` within an organization.
 */
export const zUser = z.object({
    object: z.enum(['organization.user']),
    id: z.string(),
    name: z.string(),
    email: z.string(),
    role: z.enum(['owner', 'reader']),
    added_at: z.int()
});

export const zUserDeleteResponse = z.object({
    object: z.enum(['organization.user.deleted']),
    id: z.string(),
    deleted: z.boolean()
});

export const zUserListResponse = z.object({
    object: z.enum(['list']),
    data: z.array(zUser),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zUserRoleUpdateRequest = z.object({
    role: z.enum(['owner', 'reader'])
});

/**
 * Vector store expiration policy
 *
 * The expiration policy for a vector store.
 */
export const zVectorStoreExpirationAfter = z.object({
    anchor: z.enum(['last_active_at']),
    days: z.int().gte(1).lte(365)
});

export const zCreateVectorStoreRequest = z.object({
    file_ids: z.optional(z.array(z.string()).max(500)),
    name: z.optional(z.string()),
    expires_after: z.optional(zVectorStoreExpirationAfter),
    chunking_strategy: z.optional(z.union([
        zAutoChunkingStrategyRequestParam,
        zStaticChunkingStrategyRequestParam
    ])),
    metadata: z.optional(zMetadata)
});

export const zUpdateVectorStoreRequest = z.object({
    name: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    expires_after: z.optional(zVectorStoreExpirationAfter.and(z.unknown())),
    metadata: z.optional(zMetadata)
});

/**
 * Set of 16 key-value pairs that can be attached to an object. This can be
 * useful for storing additional information about the object in a structured
 * format, and querying for objects via API or the dashboard. Keys are strings
 * with a maximum length of 64 characters. Values are strings with a maximum
 * length of 512 characters, booleans, or numbers.
 *
 */
export const zVectorStoreFileAttributes = z.union([
    z.record(z.string(), z.union([
        z.string().max(512),
        z.number(),
        z.boolean()
    ])),
    z.null()
]);

export const zCreateVectorStoreFileBatchRequest = z.object({
    file_ids: z.array(z.string()).min(1).max(500),
    chunking_strategy: z.optional(zChunkingStrategyRequestParam),
    attributes: z.optional(zVectorStoreFileAttributes)
});

export const zCreateVectorStoreFileRequest = z.object({
    file_id: z.string(),
    chunking_strategy: z.optional(zChunkingStrategyRequestParam),
    attributes: z.optional(zVectorStoreFileAttributes)
});

/**
 * File search tool call
 *
 * The results of a file search tool call. See the
 * [file search guide](/docs/guides/tools-file-search) for more information.
 *
 */
export const zFileSearchToolCall = z.object({
    id: z.string(),
    type: z.enum(['file_search_call']),
    status: z.enum([
        'in_progress',
        'searching',
        'completed',
        'incomplete',
        'failed'
    ]),
    queries: z.array(z.string()),
    results: z.optional(z.union([
        z.array(z.object({
            file_id: z.optional(z.string()),
            text: z.optional(z.string()),
            filename: z.optional(z.string()),
            attributes: z.optional(zVectorStoreFileAttributes),
            score: z.optional(z.number())
        })),
        z.null()
    ]))
});

export const zUpdateVectorStoreFileAttributesRequest = z.object({
    attributes: zVectorStoreFileAttributes
});

/**
 * Vector store file batch
 *
 * A batch of files attached to a vector store.
 */
export const zVectorStoreFileBatchObject = z.object({
    id: z.string(),
    object: z.enum(['vector_store.files_batch']),
    created_at: z.int(),
    vector_store_id: z.string(),
    status: z.enum([
        'in_progress',
        'completed',
        'cancelled',
        'failed'
    ]),
    file_counts: z.object({
        in_progress: z.int(),
        completed: z.int(),
        failed: z.int(),
        cancelled: z.int(),
        total: z.int()
    })
});

/**
 * Represents the parsed content of a vector store file.
 */
export const zVectorStoreFileContentResponse = z.object({
    object: z.enum(['vector_store.file_content.page']),
    data: z.array(z.object({
        type: z.optional(z.string()),
        text: z.optional(z.string())
    })),
    has_more: z.boolean(),
    next_page: z.union([
        z.string(),
        z.null()
    ])
});

/**
 * Vector store files
 *
 * A list of files attached to a vector store.
 */
export const zVectorStoreFileObject = z.object({
    id: z.string(),
    object: z.enum(['vector_store.file']),
    usage_bytes: z.int(),
    created_at: z.int(),
    vector_store_id: z.string(),
    status: z.enum([
        'in_progress',
        'completed',
        'cancelled',
        'failed'
    ]),
    last_error: z.union([
        z.object({
            code: z.enum([
                'server_error',
                'unsupported_file',
                'invalid_file'
            ]),
            message: z.string()
        }),
        z.null()
    ]),
    chunking_strategy: z.optional(z.union([
        zStaticChunkingStrategyResponseParam,
        zOtherChunkingStrategyResponseParam
    ])),
    attributes: z.optional(zVectorStoreFileAttributes)
});

export const zListVectorStoreFilesResponse = z.object({
    object: z.string(),
    data: z.array(zVectorStoreFileObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Vector store
 *
 * A vector store is a collection of processed files can be used by the `file_search` tool.
 */
export const zVectorStoreObject = z.object({
    id: z.string(),
    object: z.enum(['vector_store']),
    created_at: z.int(),
    name: z.string(),
    usage_bytes: z.int(),
    file_counts: z.object({
        in_progress: z.int(),
        completed: z.int(),
        failed: z.int(),
        cancelled: z.int(),
        total: z.int()
    }),
    status: z.enum([
        'expired',
        'in_progress',
        'completed'
    ]),
    expires_after: z.optional(zVectorStoreExpirationAfter),
    expires_at: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    last_active_at: z.union([
        z.int(),
        z.null()
    ]),
    metadata: zMetadata
});

export const zListVectorStoresResponse = z.object({
    object: z.string(),
    data: z.array(zVectorStoreObject),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

export const zVectorStoreSearchRequest = z.object({
    query: z.union([
        z.string(),
        z.array(z.string())
    ]),
    rewrite_query: z.optional(z.boolean()).default(false),
    max_num_results: z.optional(z.int().gte(1).lte(50)).default(10),
    filters: z.optional(z.union([
        zComparisonFilter,
        zCompoundFilter
    ])),
    ranking_options: z.optional(z.object({
        ranker: z.optional(z.enum(['auto', 'default-2024-11-15'])),
        score_threshold: z.optional(z.number().gte(0).lte(1)).default(0)
    }))
});

export const zVectorStoreSearchResultContentObject = z.object({
    type: z.enum(['text']),
    text: z.string()
});

export const zVectorStoreSearchResultItem = z.object({
    file_id: z.string(),
    filename: z.string(),
    score: z.number().gte(0).lte(1),
    attributes: zVectorStoreFileAttributes,
    content: z.array(zVectorStoreSearchResultContentObject)
});

export const zVectorStoreSearchResultsPage = z.object({
    object: z.enum(['vector_store.search_results.page']),
    search_query: z.array(z.string()),
    data: z.array(zVectorStoreSearchResultItem),
    has_more: z.boolean(),
    next_page: z.union([
        z.string(),
        z.null()
    ])
});

export const zVoiceIdsShared = z.union([
    z.string(),
    z.enum([
        'alloy',
        'ash',
        'ballad',
        'coral',
        'echo',
        'fable',
        'onyx',
        'nova',
        'sage',
        'shimmer',
        'verse'
    ])
]);

export const zCreateSpeechRequest = z.object({
    model: z.union([
        z.string(),
        z.enum([
            'tts-1',
            'tts-1-hd',
            'gpt-4o-mini-tts'
        ])
    ]),
    input: z.string().max(4096),
    instructions: z.optional(z.string().max(4096)),
    voice: zVoiceIdsShared,
    response_format: z.optional(z.enum([
        'mp3',
        'opus',
        'aac',
        'flac',
        'wav',
        'pcm'
    ])),
    speed: z.optional(z.number().gte(0.25).lte(4)).default(1)
});

/**
 * The response resource.
 */
export const zRealtimeResponse = z.object({
    id: z.optional(z.string()),
    object: z.optional(z.enum(['realtime.response'])),
    status: z.optional(z.enum([
        'completed',
        'cancelled',
        'failed',
        'incomplete'
    ])),
    status_details: z.optional(z.object({
        type: z.optional(z.enum([
            'completed',
            'cancelled',
            'failed',
            'incomplete'
        ])),
        reason: z.optional(z.enum([
            'turn_detected',
            'client_cancelled',
            'max_output_tokens',
            'content_filter'
        ])),
        error: z.optional(z.object({
            type: z.optional(z.string()),
            code: z.optional(z.string())
        }))
    })),
    output: z.optional(z.array(zRealtimeConversationItem)),
    metadata: z.optional(zMetadata),
    usage: z.optional(z.object({
        total_tokens: z.optional(z.int()),
        input_tokens: z.optional(z.int()),
        output_tokens: z.optional(z.int()),
        input_token_details: z.optional(z.object({
            cached_tokens: z.optional(z.int()),
            text_tokens: z.optional(z.int()),
            audio_tokens: z.optional(z.int())
        })),
        output_token_details: z.optional(z.object({
            text_tokens: z.optional(z.int()),
            audio_tokens: z.optional(z.int())
        }))
    })),
    conversation_id: z.optional(z.string()),
    voice: z.optional(zVoiceIdsShared),
    modalities: z.optional(z.array(z.enum(['text', 'audio']))),
    output_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    temperature: z.optional(z.number()),
    max_output_tokens: z.optional(z.union([
        z.int(),
        z.enum(['inf'])
    ]))
});

/**
 * Create a new Realtime response with these parameters
 */
export const zRealtimeResponseCreateParams = z.object({
    modalities: z.optional(z.array(z.enum(['text', 'audio']))),
    instructions: z.optional(z.string()),
    voice: z.optional(zVoiceIdsShared),
    output_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    tools: z.optional(z.array(z.object({
        type: z.optional(z.enum(['function'])),
        name: z.optional(z.string()),
        description: z.optional(z.string()),
        parameters: z.optional(z.record(z.string(), z.unknown()))
    }))),
    tool_choice: z.optional(z.string()),
    temperature: z.optional(z.number()),
    max_response_output_tokens: z.optional(z.union([
        z.int(),
        z.enum(['inf'])
    ])),
    conversation: z.optional(z.union([
        z.string(),
        z.literal('auto'),
        z.literal('none')
    ])),
    metadata: z.optional(zMetadata),
    input: z.optional(z.array(zRealtimeConversationItemWithReference))
});

/**
 * This event instructs the server to create a Response, which means triggering
 * model inference. When in Server VAD mode, the server will create Responses
 * automatically.
 *
 * A Response will include at least one Item, and may have two, in which case
 * the second will be a function call. These Items will be appended to the
 * conversation history.
 *
 * The server will respond with a `response.created` event, events for Items
 * and content created, and finally a `response.done` event to indicate the
 * Response is complete.
 *
 * The `response.create` event includes inference configuration like
 * `instructions`, and `temperature`. These fields will override the Session's
 * configuration for this Response only.
 *
 */
export const zRealtimeClientEventResponseCreate = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['response.create']),
    response: z.optional(zRealtimeResponseCreateParams)
});

/**
 * Returned when a new Response is created. The first event of response creation,
 * where the response is in an initial state of `in_progress`.
 *
 */
export const zRealtimeServerEventResponseCreated = z.object({
    event_id: z.string(),
    type: z.enum(['response.created']),
    response: zRealtimeResponse
});

/**
 * Returned when a Response is done streaming. Always emitted, no matter the
 * final state. The Response object included in the `response.done` event will
 * include all output Items in the Response but will omit the raw audio data.
 *
 */
export const zRealtimeServerEventResponseDone = z.object({
    event_id: z.string(),
    type: z.enum(['response.done']),
    response: zRealtimeResponse
});

/**
 * Realtime session object configuration.
 */
export const zRealtimeSession = z.object({
    id: z.optional(z.string()),
    modalities: z.optional(z.unknown()),
    model: z.optional(z.enum([
        'gpt-4o-realtime-preview',
        'gpt-4o-realtime-preview-2024-10-01',
        'gpt-4o-realtime-preview-2024-12-17',
        'gpt-4o-mini-realtime-preview',
        'gpt-4o-mini-realtime-preview-2024-12-17'
    ])),
    instructions: z.optional(z.string()),
    voice: z.optional(zVoiceIdsShared),
    input_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    output_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    input_audio_transcription: z.optional(z.object({
        model: z.optional(z.string()),
        language: z.optional(z.string()),
        prompt: z.optional(z.string())
    })),
    turn_detection: z.optional(z.object({
        type: z.optional(z.enum(['server_vad', 'semantic_vad'])),
        eagerness: z.optional(z.enum([
            'low',
            'medium',
            'high',
            'auto'
        ])),
        threshold: z.optional(z.number()),
        prefix_padding_ms: z.optional(z.int()),
        silence_duration_ms: z.optional(z.int()),
        create_response: z.optional(z.boolean()).default(true),
        interrupt_response: z.optional(z.boolean()).default(true)
    })),
    input_audio_noise_reduction: z.optional(z.object({
        type: z.optional(z.enum(['near_field', 'far_field']))
    })).default(null),
    tools: z.optional(z.array(z.object({
        type: z.optional(z.enum(['function'])),
        name: z.optional(z.string()),
        description: z.optional(z.string()),
        parameters: z.optional(z.record(z.string(), z.unknown()))
    }))),
    tool_choice: z.optional(z.string()).default('auto'),
    temperature: z.optional(z.number()).default(0.8),
    max_response_output_tokens: z.optional(z.union([
        z.int(),
        z.enum(['inf'])
    ]))
});

/**
 * Returned when a Session is created. Emitted automatically when a new
 * connection is established as the first server event. This event will contain
 * the default Session configuration.
 *
 */
export const zRealtimeServerEventSessionCreated = z.object({
    event_id: z.string(),
    type: z.enum(['session.created']),
    session: zRealtimeSession
});

/**
 * Returned when a session is updated with a `session.update` event, unless
 * there is an error.
 *
 */
export const zRealtimeServerEventSessionUpdated = z.object({
    event_id: z.string(),
    type: z.enum(['session.updated']),
    session: zRealtimeSession
});

/**
 * A realtime server event.
 *
 */
export const zRealtimeServerEvent = z.union([
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationCreated'))
    }).and(zRealtimeServerEventConversationCreated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemCreated'))
    }).and(zRealtimeServerEventConversationItemCreated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemDeleted'))
    }).and(zRealtimeServerEventConversationItemDeleted),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemInputAudioTranscriptionCompleted'))
    }).and(zRealtimeServerEventConversationItemInputAudioTranscriptionCompleted),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemInputAudioTranscriptionDelta'))
    }).and(zRealtimeServerEventConversationItemInputAudioTranscriptionDelta),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemInputAudioTranscriptionFailed'))
    }).and(zRealtimeServerEventConversationItemInputAudioTranscriptionFailed),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemRetrieved'))
    }).and(zRealtimeServerEventConversationItemRetrieved),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventConversationItemTruncated'))
    }).and(zRealtimeServerEventConversationItemTruncated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventError'))
    }).and(zRealtimeServerEventError),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventInputAudioBufferCleared'))
    }).and(zRealtimeServerEventInputAudioBufferCleared),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventInputAudioBufferCommitted'))
    }).and(zRealtimeServerEventInputAudioBufferCommitted),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventInputAudioBufferSpeechStarted'))
    }).and(zRealtimeServerEventInputAudioBufferSpeechStarted),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventInputAudioBufferSpeechStopped'))
    }).and(zRealtimeServerEventInputAudioBufferSpeechStopped),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventRateLimitsUpdated'))
    }).and(zRealtimeServerEventRateLimitsUpdated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseAudioDelta'))
    }).and(zRealtimeServerEventResponseAudioDelta),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseAudioDone'))
    }).and(zRealtimeServerEventResponseAudioDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseAudioTranscriptDelta'))
    }).and(zRealtimeServerEventResponseAudioTranscriptDelta),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseAudioTranscriptDone'))
    }).and(zRealtimeServerEventResponseAudioTranscriptDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseContentPartAdded'))
    }).and(zRealtimeServerEventResponseContentPartAdded),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseContentPartDone'))
    }).and(zRealtimeServerEventResponseContentPartDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseCreated'))
    }).and(zRealtimeServerEventResponseCreated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseDone'))
    }).and(zRealtimeServerEventResponseDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseFunctionCallArgumentsDelta'))
    }).and(zRealtimeServerEventResponseFunctionCallArgumentsDelta),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseFunctionCallArgumentsDone'))
    }).and(zRealtimeServerEventResponseFunctionCallArgumentsDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseOutputItemAdded'))
    }).and(zRealtimeServerEventResponseOutputItemAdded),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseOutputItemDone'))
    }).and(zRealtimeServerEventResponseOutputItemDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseTextDelta'))
    }).and(zRealtimeServerEventResponseTextDelta),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventResponseTextDone'))
    }).and(zRealtimeServerEventResponseTextDone),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventSessionCreated'))
    }).and(zRealtimeServerEventSessionCreated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventSessionUpdated'))
    }).and(zRealtimeServerEventSessionUpdated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventTranscriptionSessionUpdated'))
    }).and(zRealtimeServerEventTranscriptionSessionUpdated),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventOutputAudioBufferStarted'))
    }).and(zRealtimeServerEventOutputAudioBufferStarted),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventOutputAudioBufferStopped'))
    }).and(zRealtimeServerEventOutputAudioBufferStopped),
    z.object({
        type: z.optional(z.literal('RealtimeServerEventOutputAudioBufferCleared'))
    }).and(zRealtimeServerEventOutputAudioBufferCleared)
]);

/**
 * Realtime session object configuration.
 */
export const zRealtimeSessionCreateRequest = z.object({
    modalities: z.optional(z.unknown()),
    model: z.optional(z.enum([
        'gpt-4o-realtime-preview',
        'gpt-4o-realtime-preview-2024-10-01',
        'gpt-4o-realtime-preview-2024-12-17',
        'gpt-4o-mini-realtime-preview',
        'gpt-4o-mini-realtime-preview-2024-12-17'
    ])),
    instructions: z.optional(z.string()),
    voice: z.optional(zVoiceIdsShared),
    input_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    output_audio_format: z.optional(z.enum([
        'pcm16',
        'g711_ulaw',
        'g711_alaw'
    ])),
    input_audio_transcription: z.optional(z.object({
        model: z.optional(z.string()),
        language: z.optional(z.string()),
        prompt: z.optional(z.string())
    })),
    turn_detection: z.optional(z.object({
        type: z.optional(z.enum(['server_vad', 'semantic_vad'])),
        eagerness: z.optional(z.enum([
            'low',
            'medium',
            'high',
            'auto'
        ])),
        threshold: z.optional(z.number()),
        prefix_padding_ms: z.optional(z.int()),
        silence_duration_ms: z.optional(z.int()),
        create_response: z.optional(z.boolean()).default(true),
        interrupt_response: z.optional(z.boolean()).default(true)
    })),
    input_audio_noise_reduction: z.optional(z.object({
        type: z.optional(z.enum(['near_field', 'far_field']))
    })).default(null),
    tools: z.optional(z.array(z.object({
        type: z.optional(z.enum(['function'])),
        name: z.optional(z.string()),
        description: z.optional(z.string()),
        parameters: z.optional(z.record(z.string(), z.unknown()))
    }))),
    tool_choice: z.optional(z.string()).default('auto'),
    temperature: z.optional(z.number()).default(0.8),
    max_response_output_tokens: z.optional(z.union([
        z.int(),
        z.enum(['inf'])
    ]))
});

/**
 * Send this event to update the sessions default configuration.
 * The client may send this event at any time to update any field,
 * except for `voice`. However, note that once a session has been
 * initialized with a particular `model`, it cant be changed to
 * another model using `session.update`.
 *
 * When the server receives a `session.update`, it will respond
 * with a `session.updated` event showing the full, effective configuration.
 * Only the fields that are present are updated. To clear a field like
 * `instructions`, pass an empty string.
 *
 */
export const zRealtimeClientEventSessionUpdate = z.object({
    event_id: z.optional(z.string()),
    type: z.enum(['session.update']),
    session: zRealtimeSessionCreateRequest
});

/**
 * A realtime client event.
 *
 */
export const zRealtimeClientEvent = z.union([
    z.object({
        type: z.optional(z.literal('RealtimeClientEventConversationItemCreate'))
    }).and(zRealtimeClientEventConversationItemCreate),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventConversationItemDelete'))
    }).and(zRealtimeClientEventConversationItemDelete),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventConversationItemRetrieve'))
    }).and(zRealtimeClientEventConversationItemRetrieve),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventConversationItemTruncate'))
    }).and(zRealtimeClientEventConversationItemTruncate),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventInputAudioBufferAppend'))
    }).and(zRealtimeClientEventInputAudioBufferAppend),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventInputAudioBufferClear'))
    }).and(zRealtimeClientEventInputAudioBufferClear),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventOutputAudioBufferClear'))
    }).and(zRealtimeClientEventOutputAudioBufferClear),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventInputAudioBufferCommit'))
    }).and(zRealtimeClientEventInputAudioBufferCommit),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventResponseCancel'))
    }).and(zRealtimeClientEventResponseCancel),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventResponseCreate'))
    }).and(zRealtimeClientEventResponseCreate),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventSessionUpdate'))
    }).and(zRealtimeClientEventSessionUpdate),
    z.object({
        type: z.optional(z.literal('RealtimeClientEventTranscriptionSessionUpdate'))
    }).and(zRealtimeClientEventTranscriptionSessionUpdate)
]);

/**
 * A new Realtime session configuration, with an ephermeral key. Default TTL
 * for keys is one minute.
 *
 */
export const zRealtimeSessionCreateResponse = z.object({
    client_secret: z.object({
        value: z.string(),
        expires_at: z.int()
    }),
    modalities: z.optional(z.unknown()),
    instructions: z.optional(z.string()),
    voice: z.optional(zVoiceIdsShared),
    input_audio_format: z.optional(z.string()),
    output_audio_format: z.optional(z.string()),
    input_audio_transcription: z.optional(z.object({
        model: z.optional(z.string())
    })),
    turn_detection: z.optional(z.object({
        type: z.optional(z.string()),
        threshold: z.optional(z.number()),
        prefix_padding_ms: z.optional(z.int()),
        silence_duration_ms: z.optional(z.int())
    })),
    tools: z.optional(z.array(z.object({
        type: z.optional(z.enum(['function'])),
        name: z.optional(z.string()),
        description: z.optional(z.string()),
        parameters: z.optional(z.record(z.string(), z.unknown()))
    }))),
    tool_choice: z.optional(z.string()),
    temperature: z.optional(z.number()),
    max_response_output_tokens: z.optional(z.union([
        z.int(),
        z.enum(['inf'])
    ]))
});

/**
 * Wait
 *
 * A wait action.
 *
 */
export const zWait = z.object({
    type: z.enum(['wait'])
});

export const zComputerAction = z.union([
    zClick,
    zDoubleClick,
    zDrag,
    zKeyPress,
    zMove,
    zScreenshot,
    zScroll,
    zType,
    zWait
]);

/**
 * Computer tool call
 *
 * A tool call to a computer use tool. See the
 * [computer use guide](/docs/guides/tools-computer-use) for more information.
 *
 */
export const zComputerToolCall = z.object({
    type: z.enum(['computer_call']),
    id: z.string(),
    call_id: z.string(),
    action: zComputerAction,
    pending_safety_checks: z.array(zComputerToolCallSafetyCheck),
    status: z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ])
});

/**
 * High level guidance for the amount of context window space to use for the
 * search. One of `low`, `medium`, or `high`. `medium` is the default.
 *
 */
export const zWebSearchContextSize = z.enum([
    'low',
    'medium',
    'high'
]);

/**
 * Web search location
 *
 * Approximate location parameters for the search.
 */
export const zWebSearchLocation = z.object({
    country: z.optional(z.string()),
    region: z.optional(z.string()),
    city: z.optional(z.string()),
    timezone: z.optional(z.string())
});

export const zCreateChatCompletionRequest = zCreateModelResponseProperties.and(z.object({
    messages: z.array(zChatCompletionRequestMessage).min(1),
    model: zModelIdsShared,
    modalities: z.optional(zResponseModalities),
    reasoning_effort: z.optional(zReasoningEffort),
    max_completion_tokens: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    frequency_penalty: z.optional(z.union([
        z.number().gte(-2).lte(2).default(0),
        z.null()
    ])).default(0),
    presence_penalty: z.optional(z.union([
        z.number().gte(-2).lte(2).default(0),
        z.null()
    ])).default(0),
    web_search_options: z.optional(z.object({
        user_location: z.optional(z.union([
            z.object({
                type: z.enum(['approximate']),
                approximate: zWebSearchLocation
            }),
            z.null()
        ])),
        search_context_size: z.optional(zWebSearchContextSize)
    })),
    top_logprobs: z.optional(z.union([
        z.int().gte(0).lte(20),
        z.null()
    ])),
    response_format: z.optional(z.union([
        zResponseFormatText,
        zResponseFormatJsonSchema,
        zResponseFormatJsonObject
    ])),
    audio: z.optional(z.union([
        z.object({
            voice: zVoiceIdsShared,
            format: z.enum([
                'wav',
                'aac',
                'mp3',
                'flac',
                'opus',
                'pcm16'
            ])
        }),
        z.null()
    ])),
    store: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false),
    stream: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false),
    stop: z.optional(zStopConfiguration),
    logit_bias: z.optional(z.union([
        z.record(z.string(), z.int()),
        z.null()
    ])).default(null),
    logprobs: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false),
    max_tokens: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    n: z.optional(z.union([
        z.int().gte(1).lte(128).default(1),
        z.null()
    ])).default(1),
    prediction: z.optional(z.union([
        zPredictionContent,
        z.null()
    ])),
    seed: z.optional(z.union([
        z.int().gte(-9223372036854776000).lte(9223372036854776000),
        z.null()
    ])),
    stream_options: z.optional(zChatCompletionStreamOptions),
    tools: z.optional(z.array(zChatCompletionTool)),
    tool_choice: z.optional(zChatCompletionToolChoiceOption),
    parallel_tool_calls: z.optional(zParallelToolCalls),
    function_call: z.optional(z.union([
        z.literal('none'),
        z.literal('auto'),
        zChatCompletionFunctionCallOption
    ])),
    functions: z.optional(z.array(zChatCompletionFunctions).min(1).max(128))
}));

/**
 * Web search tool call
 *
 * The results of a web search tool call. See the
 * [web search guide](/docs/guides/tools-web-search) for more information.
 *
 */
export const zWebSearchToolCall = z.object({
    id: z.string(),
    type: z.enum(['web_search_call']),
    status: z.enum([
        'in_progress',
        'searching',
        'completed',
        'failed'
    ])
});

/**
 * Input text
 *
 * A text input to the model.
 */
export const zInputTextContent = z.object({
    type: z.enum(['input_text']),
    text: z.string()
});

/**
 * Eval message object
 *
 * A message input to the model with a role indicating instruction following
 * hierarchy. Instructions given with the `developer` or `system` role take
 * precedence over instructions given with the `user` role. Messages with the
 * `assistant` role are presumed to have been generated by the model in previous
 * interactions.
 *
 */
export const zEvalItem = z.object({
    role: z.enum([
        'user',
        'assistant',
        'system',
        'developer'
    ]),
    content: z.union([
        z.string(),
        zInputTextContent,
        z.object({
            type: z.enum(['output_text']),
            text: z.string()
        })
    ]),
    type: z.optional(z.enum(['message']))
});

/**
 * CreateEvalItem
 *
 * A chat message that makes up the prompt or context. May include variable references to the "item" namespace, ie {{item.name}}.
 */
export const zCreateEvalItem = z.union([
    z.object({
        role: z.string(),
        content: z.string()
    }),
    zEvalItem
]);

/**
 * LabelModelGrader
 *
 * A LabelModelGrader object which uses a model to assign labels to each item
 * in the evaluation.
 *
 */
export const zCreateEvalLabelModelGrader = z.object({
    type: z.enum(['label_model']),
    name: z.string(),
    model: z.string(),
    input: z.array(zCreateEvalItem),
    labels: z.array(z.string()),
    passing_labels: z.array(z.string())
});

/**
 * ResponsesRunDataSource
 *
 * A ResponsesRunDataSource object describing a model sampling configuration.
 *
 */
export const zCreateEvalResponsesRunDataSource = z.object({
    type: z.enum(['completions']),
    input_messages: z.optional(z.union([
        z.object({
            type: z.enum(['template']),
            template: z.array(z.union([z.object({
                    role: z.string(),
                    content: z.string()
                }), zEvalItem]))
        }),
        z.object({
            type: z.enum(['item_reference']),
            item_reference: z.string()
        })
    ])),
    sampling_params: z.optional(z.object({
        temperature: z.optional(z.number()).default(1),
        max_completion_tokens: z.optional(z.int()),
        top_p: z.optional(z.number()).default(1),
        seed: z.optional(z.int()).default(42)
    })),
    model: z.optional(z.string()),
    source: z.union([
        zEvalJsonlFileContentSource,
        zEvalJsonlFileIdSource,
        zEvalResponsesSource
    ])
});

/**
 * LabelModelGrader
 *
 * A LabelModelGrader object which uses a model to assign labels to each item
 * in the evaluation.
 *
 */
export const zEvalLabelModelGrader = z.object({
    type: z.enum(['label_model']),
    name: z.string(),
    model: z.string(),
    input: z.array(zEvalItem),
    labels: z.array(z.string()),
    passing_labels: z.array(z.string())
});

/**
 * ScoreModelGrader
 *
 * A ScoreModelGrader object that uses a model to assign a score to the input.
 *
 */
export const zEvalScoreModelGrader = z.object({
    type: z.enum(['score_model']),
    name: z.string(),
    model: z.string(),
    sampling_params: z.optional(z.record(z.string(), z.unknown())),
    input: z.array(zEvalItem),
    pass_threshold: z.optional(z.number()),
    range: z.optional(z.array(z.number()))
});

/**
 * CreateEvalRequest
 */
export const zCreateEvalRequest = z.object({
    name: z.optional(z.string()),
    metadata: z.optional(zMetadata),
    data_source_config: z.union([
        zCreateEvalCustomDataSourceConfig,
        zCreateEvalLogsDataSourceConfig
    ]),
    testing_criteria: z.array(z.union([
        zCreateEvalLabelModelGrader,
        zEvalStringCheckGrader,
        zEvalTextSimilarityGrader,
        zEvalPythonGrader,
        zEvalScoreModelGrader
    ]))
});

/**
 * Eval
 *
 * An Eval object with a data source config and testing criteria.
 * An Eval represents a task to be done for your LLM integration.
 * Like:
 * - Improve the quality of my chatbot
 * - See how well my chatbot handles customer support
 * - Check if o3-mini is better at my usecase than gpt-4o
 *
 */
export const zEval = z.object({
    object: z.enum(['eval']),
    id: z.string(),
    name: z.string(),
    data_source_config: z.union([
        zEvalCustomDataSourceConfig,
        zEvalStoredCompletionsDataSourceConfig
    ]),
    testing_criteria: z.array(z.union([
        zEvalLabelModelGrader,
        zEvalStringCheckGrader,
        zEvalTextSimilarityGrader,
        zEvalPythonGrader,
        zEvalScoreModelGrader
    ])).default('eval'),
    created_at: z.int(),
    metadata: zMetadata
});

/**
 * EvalList
 *
 * An object representing a list of evals.
 *
 */
export const zEvalList = z.object({
    object: z.enum(['list']),
    data: z.array(zEval),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Input image
 *
 * An image input to the model. Learn about [image inputs](/docs/guides/vision).
 */
export const zInputImageContent = z.object({
    type: z.enum(['input_image']),
    image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    file_id: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    detail: z.enum([
        'low',
        'high',
        'auto'
    ])
});

/**
 * Input file
 *
 * A file input to the model.
 */
export const zInputFileContent = z.object({
    type: z.enum(['input_file']),
    file_id: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    filename: z.optional(z.string()),
    file_data: z.optional(z.string())
});

export const zInputContent = z.union([
    zInputTextContent,
    zInputImageContent,
    zInputFileContent
]);

/**
 * Input item content list
 *
 * A list of one or many input items to the model, containing different content
 * types.
 *
 */
export const zInputMessageContentList = z.array(zInputContent);

/**
 * Input message
 *
 * A message input to the model with a role indicating instruction following
 * hierarchy. Instructions given with the `developer` or `system` role take
 * precedence over instructions given with the `user` role. Messages with the
 * `assistant` role are presumed to have been generated by the model in previous
 * interactions.
 *
 */
export const zEasyInputMessage = z.object({
    role: z.enum([
        'user',
        'assistant',
        'system',
        'developer'
    ]),
    content: z.union([
        z.string(),
        zInputMessageContentList
    ]),
    type: z.optional(z.enum(['message']))
});

/**
 * CompletionsRunDataSource
 *
 * A CompletionsRunDataSource object describing a model sampling configuration.
 *
 */
export const zCreateEvalCompletionsRunDataSource = z.object({
    type: z.enum(['completions']),
    input_messages: z.optional(z.union([
        z.object({
            type: z.enum(['template']),
            template: z.array(z.union([zEasyInputMessage, zEvalItem]))
        }),
        z.object({
            type: z.enum(['item_reference']),
            item_reference: z.string()
        })
    ])),
    sampling_params: z.optional(z.object({
        temperature: z.optional(z.number()).default(1),
        max_completion_tokens: z.optional(z.int()),
        top_p: z.optional(z.number()).default(1),
        seed: z.optional(z.int()).default(42)
    })),
    model: z.optional(z.string()),
    source: z.union([
        zEvalJsonlFileContentSource,
        zEvalJsonlFileIdSource,
        zEvalStoredCompletionsSource
    ])
});

/**
 * CreateEvalRunRequest
 */
export const zCreateEvalRunRequest = z.object({
    name: z.optional(z.string()),
    metadata: z.optional(zMetadata),
    data_source: z.union([
        zCreateEvalJsonlRunDataSource,
        zCreateEvalCompletionsRunDataSource,
        zCreateEvalResponsesRunDataSource
    ])
});

/**
 * EvalRun
 *
 * A schema representing an evaluation run.
 *
 */
export const zEvalRun = z.object({
    object: z.enum(['eval.run']),
    id: z.string(),
    eval_id: z.string(),
    status: z.string(),
    model: z.string(),
    name: z.string(),
    created_at: z.int(),
    report_url: z.string(),
    result_counts: z.object({
        total: z.int(),
        errored: z.int(),
        failed: z.int(),
        passed: z.int()
    }),
    per_model_usage: z.array(z.object({
        model_name: z.string(),
        invocation_count: z.int(),
        prompt_tokens: z.int(),
        completion_tokens: z.int(),
        total_tokens: z.int(),
        cached_tokens: z.int()
    })),
    per_testing_criteria_results: z.array(z.object({
        testing_criteria: z.string(),
        passed: z.int(),
        failed: z.int()
    })),
    data_source: z.union([
        zCreateEvalJsonlRunDataSource,
        zCreateEvalCompletionsRunDataSource,
        zCreateEvalResponsesRunDataSource
    ]),
    metadata: zMetadata,
    error: zEvalApiError
});

/**
 * EvalRunList
 *
 * An object representing a list of runs for an evaluation.
 *
 */
export const zEvalRunList = z.object({
    object: z.enum(['list']),
    data: z.array(zEvalRun),
    first_id: z.string(),
    last_id: z.string(),
    has_more: z.boolean()
});

/**
 * Input message
 *
 * A message input to the model with a role indicating instruction following
 * hierarchy. Instructions given with the `developer` or `system` role take
 * precedence over instructions given with the `user` role.
 *
 */
export const zInputMessage = z.object({
    type: z.optional(z.enum(['message'])),
    role: z.enum([
        'user',
        'system',
        'developer'
    ]),
    status: z.optional(z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ])),
    content: zInputMessageContentList
});

export const zInputMessageResource = zInputMessage.and(z.object({
    id: z.string()
}));

export const zRankingOptions = z.object({
    ranker: z.optional(z.enum(['auto', 'default-2024-11-15'])),
    score_threshold: z.optional(z.number())
});

export const zFilters = z.union([
    zComparisonFilter,
    zCompoundFilter
]);

/**
 * File search
 *
 * A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).
 */
export const zFileSearchTool = z.object({
    type: z.enum(['file_search']),
    vector_store_ids: z.array(z.string()),
    max_num_results: z.optional(z.int()),
    ranking_options: z.optional(zRankingOptions),
    filters: z.optional(z.union([
        zFilters,
        z.unknown()
    ]))
});

/**
 * Function
 *
 * Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).
 */
export const zFunctionTool = z.object({
    type: z.enum(['function']),
    name: z.string(),
    description: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    parameters: z.union([
        z.record(z.string(), z.unknown()),
        z.unknown()
    ]),
    strict: z.union([
        z.boolean(),
        z.unknown()
    ])
});

export const zApproximateLocation = z.object({
    type: z.enum(['approximate']),
    country: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    region: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    city: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    timezone: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * Web search preview
 *
 * This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).
 */
export const zWebSearchPreviewTool = z.object({
    type: z.enum(['web_search_preview', 'web_search_preview_2025_03_11']),
    user_location: z.optional(z.union([
        zApproximateLocation,
        z.unknown()
    ])),
    search_context_size: z.optional(z.enum([
        'low',
        'medium',
        'high'
    ]))
});

/**
 * Computer use preview
 *
 * A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).
 */
export const zComputerUsePreviewTool = z.object({
    type: z.enum(['computer_use_preview']),
    environment: z.enum([
        'windows',
        'mac',
        'linux',
        'ubuntu',
        'browser'
    ]),
    display_width: z.int(),
    display_height: z.int()
});

export const zTool = z.union([
    z.object({
        type: z.literal('FileSearchTool')
    }).and(zFileSearchTool),
    z.object({
        type: z.literal('FunctionTool')
    }).and(zFunctionTool),
    z.object({
        type: z.literal('WebSearchPreviewTool')
    }).and(zWebSearchPreviewTool),
    z.object({
        type: z.literal('ComputerUsePreviewTool')
    }).and(zComputerUsePreviewTool)
]);

export const zResponseProperties = z.object({
    previous_response_id: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    model: z.optional(zModelIdsResponses),
    reasoning: z.optional(zReasoning),
    max_output_tokens: z.optional(z.union([
        z.int(),
        z.null()
    ])),
    instructions: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    text: z.optional(z.object({
        format: z.optional(zTextResponseFormatConfiguration)
    })),
    tools: z.optional(z.array(zTool)),
    tool_choice: z.optional(z.union([
        zToolChoiceOptions,
        zToolChoiceTypes,
        zToolChoiceFunction
    ])),
    truncation: z.optional(z.enum(['auto', 'disabled']))
});

/**
 * File citation
 *
 * A citation to a file.
 */
export const zFileCitationBody = z.object({
    type: z.enum(['file_citation']),
    file_id: z.string(),
    index: z.int()
});

/**
 * URL citation
 *
 * A citation for a web resource used to generate a model response.
 */
export const zUrlCitationBody = z.object({
    type: z.enum(['url_citation']),
    url: z.string(),
    start_index: z.int(),
    end_index: z.int(),
    title: z.string()
});

export const zAnnotation = z.union([
    z.object({
        type: z.literal('FileCitationBody')
    }).and(zFileCitationBody),
    z.object({
        type: z.literal('UrlCitationBody')
    }).and(zUrlCitationBody),
    z.object({
        type: z.literal('FilePath')
    }).and(zFilePath)
]);

/**
 * Emitted when a text annotation is added.
 */
export const zResponseTextAnnotationDeltaEvent = z.object({
    type: z.enum(['response.output_text.annotation.added']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    annotation_index: z.int(),
    annotation: zAnnotation
});

/**
 * Output text
 *
 * A text output from the model.
 */
export const zOutputTextContent = z.object({
    type: z.enum(['output_text']),
    text: z.string(),
    annotations: z.array(zAnnotation)
});

/**
 * Refusal
 *
 * A refusal from the model.
 */
export const zRefusalContent = z.object({
    type: z.enum(['refusal']),
    refusal: z.string()
});

export const zOutputContent = z.union([
    zOutputTextContent,
    zRefusalContent
]);

/**
 * Multi-modal input and output contents.
 *
 */
export const zContent = z.union([
    zInputContent,
    zOutputContent
]);

/**
 * Output message
 *
 * An output message from the model.
 *
 */
export const zOutputMessage = z.object({
    id: z.string(),
    type: z.enum(['message']),
    role: z.enum(['assistant']),
    content: z.array(zOutputContent),
    status: z.enum([
        'in_progress',
        'completed',
        'incomplete'
    ])
});

/**
 * Content item used to generate a response.
 *
 */
export const zItemResource = z.union([
    z.object({
        type: z.literal('InputMessageResource')
    }).and(zInputMessageResource),
    z.object({
        type: z.literal('OutputMessage')
    }).and(zOutputMessage),
    z.object({
        type: z.literal('FileSearchToolCall')
    }).and(zFileSearchToolCall),
    z.object({
        type: z.literal('ComputerToolCall')
    }).and(zComputerToolCall),
    z.object({
        type: z.literal('ComputerToolCallOutputResource')
    }).and(zComputerToolCallOutputResource),
    z.object({
        type: z.literal('WebSearchToolCall')
    }).and(zWebSearchToolCall),
    z.object({
        type: z.literal('FunctionToolCallResource')
    }).and(zFunctionToolCallResource),
    z.object({
        type: z.literal('FunctionToolCallOutputResource')
    }).and(zFunctionToolCallOutputResource)
]);

export const zOutputItem = z.union([
    z.object({
        type: z.optional(z.literal('OutputMessage'))
    }).and(zOutputMessage),
    z.object({
        type: z.optional(z.literal('FileSearchToolCall'))
    }).and(zFileSearchToolCall),
    z.object({
        type: z.optional(z.literal('FunctionToolCall'))
    }).and(zFunctionToolCall),
    z.object({
        type: z.optional(z.literal('WebSearchToolCall'))
    }).and(zWebSearchToolCall),
    z.object({
        type: z.optional(z.literal('ComputerToolCall'))
    }).and(zComputerToolCall),
    z.object({
        type: z.optional(z.literal('ReasoningItem'))
    }).and(zReasoningItem)
]);

export const zResponse = zModelResponseProperties.and(zResponseProperties).and(z.object({
    id: z.string(),
    object: z.enum(['response']),
    status: z.optional(z.enum([
        'completed',
        'failed',
        'in_progress',
        'incomplete'
    ])),
    created_at: z.number(),
    error: zResponseError,
    incomplete_details: z.union([
        z.object({
            reason: z.optional(z.enum(['max_output_tokens', 'content_filter']))
        }),
        z.null()
    ]),
    output: z.array(zOutputItem),
    output_text: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    usage: z.optional(zResponseUsage),
    parallel_tool_calls: z.boolean().default(true)
}));

/**
 * Emitted when the model response is complete.
 */
export const zResponseCompletedEvent = z.object({
    type: z.enum(['response.completed']),
    response: zResponse
});

/**
 * Emitted when a new content part is added.
 */
export const zResponseContentPartAddedEvent = z.object({
    type: z.enum(['response.content_part.added']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    part: zOutputContent
});

/**
 * Emitted when a content part is done.
 */
export const zResponseContentPartDoneEvent = z.object({
    type: z.enum(['response.content_part.done']),
    item_id: z.string(),
    output_index: z.int(),
    content_index: z.int(),
    part: zOutputContent
});

/**
 * An event that is emitted when a response is created.
 *
 */
export const zResponseCreatedEvent = z.object({
    type: z.enum(['response.created']),
    response: zResponse
});

/**
 * An event that is emitted when a response fails.
 *
 */
export const zResponseFailedEvent = z.object({
    type: z.enum(['response.failed']),
    response: zResponse
});

/**
 * Emitted when the response is in progress.
 */
export const zResponseInProgressEvent = z.object({
    type: z.enum(['response.in_progress']),
    response: zResponse
});

/**
 * An event that is emitted when a response finishes as incomplete.
 *
 */
export const zResponseIncompleteEvent = z.object({
    type: z.enum(['response.incomplete']),
    response: zResponse
});

/**
 * A list of Response items.
 */
export const zResponseItemList = z.object({
    object: z.enum(['list']),
    data: z.array(zItemResource),
    has_more: z.boolean(),
    first_id: z.string(),
    last_id: z.string()
});

/**
 * Emitted when a new output item is added.
 */
export const zResponseOutputItemAddedEvent = z.object({
    type: z.enum(['response.output_item.added']),
    output_index: z.int(),
    item: zOutputItem
});

/**
 * Emitted when an output item is marked done.
 */
export const zResponseOutputItemDoneEvent = z.object({
    type: z.enum(['response.output_item.done']),
    output_index: z.int(),
    item: zOutputItem
});

export const zResponseStreamEvent = z.union([
    z.object({
        type: z.optional(z.literal('ResponseAudioDeltaEvent'))
    }).and(zResponseAudioDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseAudioDoneEvent'))
    }).and(zResponseAudioDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseAudioTranscriptDeltaEvent'))
    }).and(zResponseAudioTranscriptDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseAudioTranscriptDoneEvent'))
    }).and(zResponseAudioTranscriptDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseCodeInterpreterCallCodeDeltaEvent'))
    }).and(zResponseCodeInterpreterCallCodeDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseCodeInterpreterCallCodeDoneEvent'))
    }).and(zResponseCodeInterpreterCallCodeDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseCodeInterpreterCallCompletedEvent'))
    }).and(zResponseCodeInterpreterCallCompletedEvent),
    z.object({
        type: z.optional(z.literal('ResponseCodeInterpreterCallInProgressEvent'))
    }).and(zResponseCodeInterpreterCallInProgressEvent),
    z.object({
        type: z.optional(z.literal('ResponseCodeInterpreterCallInterpretingEvent'))
    }).and(zResponseCodeInterpreterCallInterpretingEvent),
    z.object({
        type: z.optional(z.literal('ResponseCompletedEvent'))
    }).and(zResponseCompletedEvent),
    z.object({
        type: z.optional(z.literal('ResponseContentPartAddedEvent'))
    }).and(zResponseContentPartAddedEvent),
    z.object({
        type: z.optional(z.literal('ResponseContentPartDoneEvent'))
    }).and(zResponseContentPartDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseCreatedEvent'))
    }).and(zResponseCreatedEvent),
    z.object({
        type: z.optional(z.literal('ResponseErrorEvent'))
    }).and(zResponseErrorEvent),
    z.object({
        type: z.optional(z.literal('ResponseFileSearchCallCompletedEvent'))
    }).and(zResponseFileSearchCallCompletedEvent),
    z.object({
        type: z.optional(z.literal('ResponseFileSearchCallInProgressEvent'))
    }).and(zResponseFileSearchCallInProgressEvent),
    z.object({
        type: z.optional(z.literal('ResponseFileSearchCallSearchingEvent'))
    }).and(zResponseFileSearchCallSearchingEvent),
    z.object({
        type: z.optional(z.literal('ResponseFunctionCallArgumentsDeltaEvent'))
    }).and(zResponseFunctionCallArgumentsDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseFunctionCallArgumentsDoneEvent'))
    }).and(zResponseFunctionCallArgumentsDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseInProgressEvent'))
    }).and(zResponseInProgressEvent),
    z.object({
        type: z.optional(z.literal('ResponseFailedEvent'))
    }).and(zResponseFailedEvent),
    z.object({
        type: z.optional(z.literal('ResponseIncompleteEvent'))
    }).and(zResponseIncompleteEvent),
    z.object({
        type: z.optional(z.literal('ResponseOutputItemAddedEvent'))
    }).and(zResponseOutputItemAddedEvent),
    z.object({
        type: z.optional(z.literal('ResponseOutputItemDoneEvent'))
    }).and(zResponseOutputItemDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseReasoningSummaryPartAddedEvent'))
    }).and(zResponseReasoningSummaryPartAddedEvent),
    z.object({
        type: z.optional(z.literal('ResponseReasoningSummaryPartDoneEvent'))
    }).and(zResponseReasoningSummaryPartDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseReasoningSummaryTextDeltaEvent'))
    }).and(zResponseReasoningSummaryTextDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseReasoningSummaryTextDoneEvent'))
    }).and(zResponseReasoningSummaryTextDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseRefusalDeltaEvent'))
    }).and(zResponseRefusalDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseRefusalDoneEvent'))
    }).and(zResponseRefusalDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseTextAnnotationDeltaEvent'))
    }).and(zResponseTextAnnotationDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseTextDeltaEvent'))
    }).and(zResponseTextDeltaEvent),
    z.object({
        type: z.optional(z.literal('ResponseTextDoneEvent'))
    }).and(zResponseTextDoneEvent),
    z.object({
        type: z.optional(z.literal('ResponseWebSearchCallCompletedEvent'))
    }).and(zResponseWebSearchCallCompletedEvent),
    z.object({
        type: z.optional(z.literal('ResponseWebSearchCallInProgressEvent'))
    }).and(zResponseWebSearchCallInProgressEvent),
    z.object({
        type: z.optional(z.literal('ResponseWebSearchCallSearchingEvent'))
    }).and(zResponseWebSearchCallSearchingEvent)
]);

/**
 * A pending safety check for the computer call.
 */
export const zComputerCallSafetyCheckParam = z.object({
    id: z.string(),
    code: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    message: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * Computer tool call output
 *
 * The output of a computer tool call.
 */
export const zComputerCallOutputItemParam = z.object({
    id: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    call_id: z.string().min(1).max(64),
    type: z.enum(['computer_call_output']),
    output: zComputerScreenshotImage,
    acknowledged_safety_checks: z.optional(z.union([
        z.array(zComputerCallSafetyCheckParam),
        z.unknown()
    ])),
    status: z.optional(z.union([
        z.enum([
            'in_progress',
            'completed',
            'incomplete'
        ]),
        z.unknown()
    ]))
});

/**
 * Function tool call output
 *
 * The output of a function tool call.
 */
export const zFunctionCallOutputItemParam = z.object({
    id: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    call_id: z.string().min(1).max(64),
    type: z.enum(['function_call_output']),
    output: z.string().max(10485760),
    status: z.optional(z.union([
        z.enum([
            'in_progress',
            'completed',
            'incomplete'
        ]),
        z.unknown()
    ]))
});

/**
 * Content item used to generate a response.
 *
 */
export const zItem = z.union([
    z.object({
        type: z.literal('InputMessage')
    }).and(zInputMessage),
    z.object({
        type: z.literal('OutputMessage')
    }).and(zOutputMessage),
    z.object({
        type: z.literal('FileSearchToolCall')
    }).and(zFileSearchToolCall),
    z.object({
        type: z.literal('ComputerToolCall')
    }).and(zComputerToolCall),
    z.object({
        type: z.literal('ComputerCallOutputItemParam')
    }).and(zComputerCallOutputItemParam),
    z.object({
        type: z.literal('WebSearchToolCall')
    }).and(zWebSearchToolCall),
    z.object({
        type: z.literal('FunctionToolCall')
    }).and(zFunctionToolCall),
    z.object({
        type: z.literal('FunctionCallOutputItemParam')
    }).and(zFunctionCallOutputItemParam),
    z.object({
        type: z.literal('ReasoningItem')
    }).and(zReasoningItem)
]);

/**
 * Item reference
 *
 * An internal identifier for an item to reference.
 */
export const zItemReferenceParam = z.object({
    type: z.optional(z.union([
        z.enum(['item_reference']),
        z.unknown()
    ])),
    id: z.string()
});

export const zInputItem = z.union([
    z.object({
        type: z.literal('EasyInputMessage')
    }).and(zEasyInputMessage),
    z.object({
        type: z.literal('Item')
    }).and(zItem),
    z.object({
        type: z.literal('ItemReferenceParam')
    }).and(zItemReferenceParam)
]);

export const zCreateResponse = zCreateModelResponseProperties.and(zResponseProperties).and(z.object({
    input: z.union([
        z.string(),
        z.array(zInputItem)
    ]),
    include: z.optional(z.union([
        z.array(zIncludable),
        z.null()
    ])),
    parallel_tool_calls: z.optional(z.union([
        z.boolean().default(true),
        z.null()
    ])).default(true),
    store: z.optional(z.union([
        z.boolean().default(true),
        z.null()
    ])).default(true),
    stream: z.optional(z.union([
        z.boolean().default(false),
        z.null()
    ])).default(false)
}));
